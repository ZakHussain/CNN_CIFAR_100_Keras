{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practicing Convolutional Neural Networks CIFAR 100 Challenge  \n",
    "**Author: Zak Hussain**  \n",
    "**Date: 12/13/2019**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Purpose:**  \n",
    "The purpose of this notebook is to use Neural nets to perform classificaiton on the the CIFAR 100 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import in keras tools that will be used**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import cifar100\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check that GPU is enabled**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 2154041625520619214\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4937233203\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 2119555287756550214\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define a method to plot a visual to check for overfitting (found on keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "# plot diagnostic learning curves (from keras)\n",
    "def plot_acc_and_cel(history):\n",
    "    # plot loss\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Cross Entropy Loss')\n",
    "    pyplot.plot(history.history['loss'], color='green', label='train')\n",
    "    pyplot.plot(history.history['val_loss'], color='orange', label='validation')\n",
    "    # plot accuracy\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Classification Accuracy')\n",
    "    pyplot.plot(history.history['accuracy'], color='green', label='train')\n",
    "    pyplot.plot(history.history['val_accuracy'], color='orange', label='validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial Setup: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "num_classes = 100\n",
    "epochs = 200\n",
    "\n",
    "# get the data, split between (x,y) and test sets:\n",
    "(X, y), (X_test, y_test) = cifar100.load_data()\n",
    "\n",
    "# normalize values between 0 and 1\n",
    "X = X.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "# Convert categorical info using one-hot-encoding.\n",
    "y = keras.utils.to_categorical(y, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# use sklearn to form the dev set from X and y\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(X, y, test_size=.05) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (47500, 32, 32, 3)\n",
      "47500 train samples\n",
      "2500 validation samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_dev.shape[0], 'validation samples') \n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define a Baseline Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_VGG_model(): \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dense(100, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile and fit a baseline model using sgd optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD\n",
    "\n",
    "# compile model\n",
    "baseline_model = make_VGG_model()\n",
    "\n",
    "# compile baseline with SGD optimizer model\n",
    "sgd_opt = SGD(lr=0.001, momentum=0.9)\n",
    "baseline_model.compile(optimizer=sgd_opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/200\n",
      "47500/47500 [==============================] - 12s 254us/step - loss: 4.3896 - accuracy: 0.0444 - val_loss: 4.0459 - val_accuracy: 0.0936\n",
      "Epoch 2/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 3.8403 - accuracy: 0.1187 - val_loss: 3.6999 - val_accuracy: 0.1436\n",
      "Epoch 3/200\n",
      "47500/47500 [==============================] - 10s 214us/step - loss: 3.4823 - accuracy: 0.1776 - val_loss: 3.4069 - val_accuracy: 0.1904\n",
      "Epoch 4/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 3.2271 - accuracy: 0.2208 - val_loss: 3.2755 - val_accuracy: 0.2260\n",
      "Epoch 5/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 3.0165 - accuracy: 0.2600 - val_loss: 3.0915 - val_accuracy: 0.2588\n",
      "Epoch 6/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 2.8338 - accuracy: 0.2979 - val_loss: 2.9541 - val_accuracy: 0.2740\n",
      "Epoch 7/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 2.6694 - accuracy: 0.3295 - val_loss: 2.8778 - val_accuracy: 0.2832\n",
      "Epoch 8/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 2.5247 - accuracy: 0.3593 - val_loss: 2.7780 - val_accuracy: 0.3172\n",
      "Epoch 9/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 2.3890 - accuracy: 0.3879 - val_loss: 2.7131 - val_accuracy: 0.3324\n",
      "Epoch 10/200\n",
      "47500/47500 [==============================] - 10s 214us/step - loss: 2.2611 - accuracy: 0.4153 - val_loss: 2.6763 - val_accuracy: 0.3396\n",
      "Epoch 11/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 2.1335 - accuracy: 0.4454 - val_loss: 2.6905 - val_accuracy: 0.3472\n",
      "Epoch 12/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 2.0117 - accuracy: 0.4699 - val_loss: 2.5911 - val_accuracy: 0.3660\n",
      "Epoch 13/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 1.8958 - accuracy: 0.4959 - val_loss: 2.5712 - val_accuracy: 0.3692\n",
      "Epoch 14/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 1.7767 - accuracy: 0.5214 - val_loss: 2.6136 - val_accuracy: 0.3612\n",
      "Epoch 15/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 1.6596 - accuracy: 0.5498 - val_loss: 2.7475 - val_accuracy: 0.3616\n",
      "Epoch 16/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 1.5486 - accuracy: 0.5751 - val_loss: 2.6125 - val_accuracy: 0.3812\n",
      "Epoch 17/200\n",
      "47500/47500 [==============================] - 10s 214us/step - loss: 1.4348 - accuracy: 0.6043 - val_loss: 2.7231 - val_accuracy: 0.3816\n",
      "Epoch 18/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 1.3281 - accuracy: 0.6303 - val_loss: 2.7956 - val_accuracy: 0.3736\n",
      "Epoch 19/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 1.2138 - accuracy: 0.6562 - val_loss: 2.9457 - val_accuracy: 0.3564\n",
      "Epoch 20/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 1.1090 - accuracy: 0.6824 - val_loss: 3.0517 - val_accuracy: 0.3692\n",
      "Epoch 21/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 1.0100 - accuracy: 0.7084 - val_loss: 3.1906 - val_accuracy: 0.3684\n",
      "Epoch 22/200\n",
      "47500/47500 [==============================] - 10s 214us/step - loss: 0.9130 - accuracy: 0.7300 - val_loss: 3.2353 - val_accuracy: 0.3456\n",
      "Epoch 23/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 0.8237 - accuracy: 0.7529 - val_loss: 3.4879 - val_accuracy: 0.3596\n",
      "Epoch 24/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 0.7244 - accuracy: 0.7804 - val_loss: 3.6158 - val_accuracy: 0.3652\n",
      "Epoch 25/200\n",
      "47500/47500 [==============================] - 10s 211us/step - loss: 0.6394 - accuracy: 0.8035 - val_loss: 3.9406 - val_accuracy: 0.3588\n",
      "Epoch 26/200\n",
      "47500/47500 [==============================] - 10s 206us/step - loss: 0.5796 - accuracy: 0.8200 - val_loss: 3.9496 - val_accuracy: 0.3544\n",
      "Epoch 27/200\n",
      "47500/47500 [==============================] - 10s 207us/step - loss: 0.5254 - accuracy: 0.8328 - val_loss: 4.1508 - val_accuracy: 0.3564\n",
      "Epoch 28/200\n",
      "47500/47500 [==============================] - 10s 207us/step - loss: 0.4772 - accuracy: 0.8467 - val_loss: 4.3327 - val_accuracy: 0.3628\n",
      "Epoch 29/200\n",
      "47500/47500 [==============================] - 10s 207us/step - loss: 0.4127 - accuracy: 0.8666 - val_loss: 4.6824 - val_accuracy: 0.3624\n",
      "Epoch 30/200\n",
      "47500/47500 [==============================] - 10s 211us/step - loss: 0.3904 - accuracy: 0.8714 - val_loss: 4.7770 - val_accuracy: 0.3488\n",
      "Epoch 31/200\n",
      "47500/47500 [==============================] - 10s 207us/step - loss: 0.3753 - accuracy: 0.8765 - val_loss: 4.7965 - val_accuracy: 0.3484\n",
      "Epoch 32/200\n",
      "47500/47500 [==============================] - 10s 207us/step - loss: 0.3102 - accuracy: 0.8982 - val_loss: 4.9609 - val_accuracy: 0.3564\n",
      "Epoch 33/200\n",
      "47500/47500 [==============================] - 10s 208us/step - loss: 0.2945 - accuracy: 0.9036 - val_loss: 5.4930 - val_accuracy: 0.3496\n",
      "Epoch 34/200\n",
      "47500/47500 [==============================] - 10s 208us/step - loss: 0.2570 - accuracy: 0.9152 - val_loss: 5.5640 - val_accuracy: 0.3548\n",
      "Epoch 35/200\n",
      "47500/47500 [==============================] - 10s 209us/step - loss: 0.2512 - accuracy: 0.9171 - val_loss: 5.7168 - val_accuracy: 0.3396\n",
      "Epoch 36/200\n",
      "47500/47500 [==============================] - 10s 208us/step - loss: 0.2321 - accuracy: 0.9224 - val_loss: 5.7148 - val_accuracy: 0.3632\n",
      "Epoch 37/200\n",
      "47500/47500 [==============================] - 10s 210us/step - loss: 0.2097 - accuracy: 0.9309 - val_loss: 6.1691 - val_accuracy: 0.3532\n",
      "Epoch 38/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.2192 - accuracy: 0.9270 - val_loss: 6.0927 - val_accuracy: 0.3544\n",
      "Epoch 39/200\n",
      "47500/47500 [==============================] - 10s 214us/step - loss: 0.2037 - accuracy: 0.9324 - val_loss: 6.1152 - val_accuracy: 0.3600\n",
      "Epoch 40/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 0.1791 - accuracy: 0.9397 - val_loss: 6.2838 - val_accuracy: 0.3548\n",
      "Epoch 41/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.1817 - accuracy: 0.9415 - val_loss: 6.2595 - val_accuracy: 0.3560\n",
      "Epoch 42/200\n",
      "47500/47500 [==============================] - 10s 211us/step - loss: 0.1896 - accuracy: 0.9373 - val_loss: 6.3319 - val_accuracy: 0.3568\n",
      "Epoch 43/200\n",
      "47500/47500 [==============================] - 10s 211us/step - loss: 0.1668 - accuracy: 0.9439 - val_loss: 6.0694 - val_accuracy: 0.3608\n",
      "Epoch 44/200\n",
      "47500/47500 [==============================] - 11s 221us/step - loss: 0.1536 - accuracy: 0.9488 - val_loss: 6.8464 - val_accuracy: 0.3568\n",
      "Epoch 45/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.1600 - accuracy: 0.9476 - val_loss: 6.5679 - val_accuracy: 0.3484\n",
      "Epoch 46/200\n",
      "47500/47500 [==============================] - 10s 219us/step - loss: 0.1341 - accuracy: 0.9556 - val_loss: 6.8197 - val_accuracy: 0.3600\n",
      "Epoch 47/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.1232 - accuracy: 0.9588 - val_loss: 7.0179 - val_accuracy: 0.3572\n",
      "Epoch 48/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.1277 - accuracy: 0.9585 - val_loss: 6.9944 - val_accuracy: 0.3616\n",
      "Epoch 49/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.1108 - accuracy: 0.9644 - val_loss: 7.0482 - val_accuracy: 0.3624\n",
      "Epoch 50/200\n",
      "47500/47500 [==============================] - 10s 214us/step - loss: 0.1110 - accuracy: 0.9638 - val_loss: 7.2552 - val_accuracy: 0.3516\n",
      "Epoch 51/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.1142 - accuracy: 0.9634 - val_loss: 7.1782 - val_accuracy: 0.3532\n",
      "Epoch 52/200\n",
      "47500/47500 [==============================] - 10s 221us/step - loss: 0.0981 - accuracy: 0.9682 - val_loss: 7.6427 - val_accuracy: 0.3488\n",
      "Epoch 53/200\n",
      "47500/47500 [==============================] - 10s 219us/step - loss: 0.1045 - accuracy: 0.9657 - val_loss: 7.3862 - val_accuracy: 0.3476\n",
      "Epoch 54/200\n",
      "47500/47500 [==============================] - 10s 217us/step - loss: 0.0964 - accuracy: 0.9685 - val_loss: 7.6205 - val_accuracy: 0.3508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200\n",
      "47500/47500 [==============================] - 10s 210us/step - loss: 0.1098 - accuracy: 0.9642 - val_loss: 7.7923 - val_accuracy: 0.3608\n",
      "Epoch 56/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 0.1117 - accuracy: 0.9645 - val_loss: 7.8656 - val_accuracy: 0.3388\n",
      "Epoch 57/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.0860 - accuracy: 0.9721 - val_loss: 7.6080 - val_accuracy: 0.3640\n",
      "Epoch 58/200\n",
      "47500/47500 [==============================] - 10s 213us/step - loss: 0.0919 - accuracy: 0.9697 - val_loss: 7.4716 - val_accuracy: 0.3652\n",
      "Epoch 59/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 0.0853 - accuracy: 0.9731 - val_loss: 7.8778 - val_accuracy: 0.3468\n",
      "Epoch 60/200\n",
      "47500/47500 [==============================] - 10s 211us/step - loss: 0.0894 - accuracy: 0.9712 - val_loss: 7.9257 - val_accuracy: 0.3484\n",
      "Epoch 61/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.0955 - accuracy: 0.9677 - val_loss: 7.5950 - val_accuracy: 0.3608\n",
      "Epoch 62/200\n",
      "47500/47500 [==============================] - 10s 214us/step - loss: 0.0681 - accuracy: 0.9782 - val_loss: 7.6873 - val_accuracy: 0.3632\n",
      "Epoch 63/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.0742 - accuracy: 0.9759 - val_loss: 8.1104 - val_accuracy: 0.3708\n",
      "Epoch 64/200\n",
      "47500/47500 [==============================] - 10s 211us/step - loss: 0.0621 - accuracy: 0.9795 - val_loss: 8.2622 - val_accuracy: 0.3592\n",
      "Epoch 65/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 0.0747 - accuracy: 0.9761 - val_loss: 8.1484 - val_accuracy: 0.3740\n",
      "Epoch 66/200\n",
      "47500/47500 [==============================] - 10s 214us/step - loss: 0.0662 - accuracy: 0.9794 - val_loss: 8.6677 - val_accuracy: 0.3584\n",
      "Epoch 67/200\n",
      "47500/47500 [==============================] - 10s 213us/step - loss: 0.0682 - accuracy: 0.9782 - val_loss: 8.3999 - val_accuracy: 0.3568\n",
      "Epoch 68/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0670 - accuracy: 0.9790 - val_loss: 8.3698 - val_accuracy: 0.3632\n",
      "Epoch 69/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.0776 - accuracy: 0.9748 - val_loss: 8.5510 - val_accuracy: 0.3544\n",
      "Epoch 70/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 0.0897 - accuracy: 0.9710 - val_loss: 8.1967 - val_accuracy: 0.3640\n",
      "Epoch 71/200\n",
      "47500/47500 [==============================] - 10s 214us/step - loss: 0.0615 - accuracy: 0.9802 - val_loss: 8.4994 - val_accuracy: 0.3532\n",
      "Epoch 72/200\n",
      "47500/47500 [==============================] - 10s 214us/step - loss: 0.0635 - accuracy: 0.9799 - val_loss: 8.0264 - val_accuracy: 0.3608\n",
      "Epoch 73/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0595 - accuracy: 0.9807 - val_loss: 8.6144 - val_accuracy: 0.3624\n",
      "Epoch 74/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0691 - accuracy: 0.9779 - val_loss: 8.5134 - val_accuracy: 0.3620\n",
      "Epoch 75/200\n",
      "47500/47500 [==============================] - 10s 217us/step - loss: 0.0528 - accuracy: 0.9837 - val_loss: 8.6576 - val_accuracy: 0.3676\n",
      "Epoch 76/200\n",
      "47500/47500 [==============================] - 10s 213us/step - loss: 0.0388 - accuracy: 0.9877 - val_loss: 8.7079 - val_accuracy: 0.3672\n",
      "Epoch 77/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 0.0563 - accuracy: 0.9821 - val_loss: 8.5199 - val_accuracy: 0.3616\n",
      "Epoch 78/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 0.0457 - accuracy: 0.9855 - val_loss: 8.8095 - val_accuracy: 0.3660\n",
      "Epoch 79/200\n",
      "47500/47500 [==============================] - 10s 211us/step - loss: 0.0633 - accuracy: 0.9805 - val_loss: 8.8150 - val_accuracy: 0.3564\n",
      "Epoch 80/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0727 - accuracy: 0.9773 - val_loss: 8.8990 - val_accuracy: 0.3480\n",
      "Epoch 81/200\n",
      "47500/47500 [==============================] - 10s 213us/step - loss: 0.0696 - accuracy: 0.9772 - val_loss: 8.7939 - val_accuracy: 0.3544\n",
      "Epoch 82/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 0.0518 - accuracy: 0.9836 - val_loss: 9.0950 - val_accuracy: 0.3528\n",
      "Epoch 83/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 0.0602 - accuracy: 0.9807 - val_loss: 8.8947 - val_accuracy: 0.3552\n",
      "Epoch 84/200\n",
      "47500/47500 [==============================] - 10s 213us/step - loss: 0.0468 - accuracy: 0.9850 - val_loss: 8.9741 - val_accuracy: 0.3556\n",
      "Epoch 85/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0515 - accuracy: 0.9835 - val_loss: 9.4987 - val_accuracy: 0.3632\n",
      "Epoch 86/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.0423 - accuracy: 0.9862 - val_loss: 9.3803 - val_accuracy: 0.3700\n",
      "Epoch 87/200\n",
      "47500/47500 [==============================] - 10s 211us/step - loss: 0.0485 - accuracy: 0.9845 - val_loss: 8.8884 - val_accuracy: 0.3612\n",
      "Epoch 88/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.0608 - accuracy: 0.9803 - val_loss: 8.9925 - val_accuracy: 0.3592\n",
      "Epoch 89/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0736 - accuracy: 0.9765 - val_loss: 8.7844 - val_accuracy: 0.3616\n",
      "Epoch 90/200\n",
      "47500/47500 [==============================] - 10s 213us/step - loss: 0.0588 - accuracy: 0.9808 - val_loss: 9.3804 - val_accuracy: 0.3692\n",
      "Epoch 91/200\n",
      "47500/47500 [==============================] - 11s 241us/step - loss: 0.0458 - accuracy: 0.9855 - val_loss: 9.1122 - val_accuracy: 0.3720\n",
      "Epoch 92/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0407 - accuracy: 0.9865 - val_loss: 9.1087 - val_accuracy: 0.3660\n",
      "Epoch 93/200\n",
      "47500/47500 [==============================] - 10s 217us/step - loss: 0.0395 - accuracy: 0.9874 - val_loss: 9.1330 - val_accuracy: 0.3656\n",
      "Epoch 94/200\n",
      "47500/47500 [==============================] - 10s 217us/step - loss: 0.0463 - accuracy: 0.9852 - val_loss: 9.1272 - val_accuracy: 0.3668\n",
      "Epoch 95/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0426 - accuracy: 0.9864 - val_loss: 9.3824 - val_accuracy: 0.3700\n",
      "Epoch 96/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0400 - accuracy: 0.9873 - val_loss: 9.2495 - val_accuracy: 0.3584\n",
      "Epoch 97/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 0.0556 - accuracy: 0.9827 - val_loss: 9.5593 - val_accuracy: 0.3660\n",
      "Epoch 98/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0691 - accuracy: 0.9784 - val_loss: 9.0177 - val_accuracy: 0.3616\n",
      "Epoch 99/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0498 - accuracy: 0.9839 - val_loss: 9.4869 - val_accuracy: 0.3628\n",
      "Epoch 100/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 0.0446 - accuracy: 0.9852 - val_loss: 9.6991 - val_accuracy: 0.3688\n",
      "Epoch 101/200\n",
      "47500/47500 [==============================] - 10s 214us/step - loss: 0.0502 - accuracy: 0.9841 - val_loss: 9.4934 - val_accuracy: 0.3560\n",
      "Epoch 102/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 0.0549 - accuracy: 0.9827 - val_loss: 9.3760 - val_accuracy: 0.3668\n",
      "Epoch 103/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 0.0454 - accuracy: 0.9858 - val_loss: 9.5842 - val_accuracy: 0.3656\n",
      "Epoch 104/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 0.0401 - accuracy: 0.9868 - val_loss: 9.9120 - val_accuracy: 0.3548\n",
      "Epoch 105/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0278 - accuracy: 0.9909 - val_loss: 10.1688 - val_accuracy: 0.3676\n",
      "Epoch 106/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 0.0455 - accuracy: 0.9859 - val_loss: 9.8209 - val_accuracy: 0.3648\n",
      "Epoch 107/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0457 - accuracy: 0.9863 - val_loss: 9.2703 - val_accuracy: 0.3668\n",
      "Epoch 108/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 0.0344 - accuracy: 0.9897 - val_loss: 9.6949 - val_accuracy: 0.3524\n",
      "Epoch 109/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0229 - accuracy: 0.9931 - val_loss: 9.9435 - val_accuracy: 0.3656\n",
      "Epoch 110/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0137 - accuracy: 0.9963 - val_loss: 10.1502 - val_accuracy: 0.3688\n",
      "Epoch 111/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0216 - accuracy: 0.9935 - val_loss: 9.9582 - val_accuracy: 0.3688\n",
      "Epoch 112/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0264 - accuracy: 0.9919 - val_loss: 10.2001 - val_accuracy: 0.3664\n",
      "Epoch 113/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0333 - accuracy: 0.9897 - val_loss: 9.8208 - val_accuracy: 0.3704\n",
      "Epoch 114/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 0.0226 - accuracy: 0.9930 - val_loss: 10.0598 - val_accuracy: 0.3592\n",
      "Epoch 115/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 0.0359 - accuracy: 0.9887 - val_loss: 10.2511 - val_accuracy: 0.3680\n",
      "Epoch 116/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0385 - accuracy: 0.9882 - val_loss: 10.1097 - val_accuracy: 0.3680\n",
      "Epoch 117/200\n",
      "47500/47500 [==============================] - 10s 217us/step - loss: 0.0332 - accuracy: 0.9892 - val_loss: 9.8225 - val_accuracy: 0.3560\n",
      "Epoch 118/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0320 - accuracy: 0.9895 - val_loss: 9.9843 - val_accuracy: 0.3628\n",
      "Epoch 119/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0353 - accuracy: 0.9890 - val_loss: 9.9233 - val_accuracy: 0.3580\n",
      "Epoch 120/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0325 - accuracy: 0.9893 - val_loss: 10.2436 - val_accuracy: 0.3732\n",
      "Epoch 121/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0401 - accuracy: 0.9870 - val_loss: 9.9244 - val_accuracy: 0.3536\n",
      "Epoch 122/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0432 - accuracy: 0.9863 - val_loss: 10.4358 - val_accuracy: 0.3672\n",
      "Epoch 123/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0281 - accuracy: 0.9909 - val_loss: 10.1729 - val_accuracy: 0.3500\n",
      "Epoch 124/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 0.0234 - accuracy: 0.9929 - val_loss: 9.8544 - val_accuracy: 0.3752\n",
      "Epoch 125/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0207 - accuracy: 0.9940 - val_loss: 10.3665 - val_accuracy: 0.3596\n",
      "Epoch 126/200\n",
      "47500/47500 [==============================] - 10s 217us/step - loss: 0.0444 - accuracy: 0.9862 - val_loss: 9.8291 - val_accuracy: 0.3564\n",
      "Epoch 127/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0358 - accuracy: 0.9882 - val_loss: 10.0947 - val_accuracy: 0.3556\n",
      "Epoch 128/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0480 - accuracy: 0.9856 - val_loss: 10.3977 - val_accuracy: 0.3476\n",
      "Epoch 129/200\n",
      "47500/47500 [==============================] - 10s 217us/step - loss: 0.0433 - accuracy: 0.9865 - val_loss: 10.0753 - val_accuracy: 0.3504\n",
      "Epoch 130/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 0.0417 - accuracy: 0.9870 - val_loss: 10.1741 - val_accuracy: 0.3588\n",
      "Epoch 131/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0405 - accuracy: 0.9874 - val_loss: 10.1269 - val_accuracy: 0.3572\n",
      "Epoch 132/200\n",
      "47500/47500 [==============================] - 10s 217us/step - loss: 0.0367 - accuracy: 0.9888 - val_loss: 10.1910 - val_accuracy: 0.3596\n",
      "Epoch 133/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0439 - accuracy: 0.9867 - val_loss: 9.9782 - val_accuracy: 0.3616\n",
      "Epoch 134/200\n",
      "47500/47500 [==============================] - 10s 217us/step - loss: 0.0431 - accuracy: 0.9861 - val_loss: 9.8871 - val_accuracy: 0.3656\n",
      "Epoch 135/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0348 - accuracy: 0.9891 - val_loss: 10.0118 - val_accuracy: 0.3624\n",
      "Epoch 136/200\n",
      "47500/47500 [==============================] - 10s 217us/step - loss: 0.0326 - accuracy: 0.9899 - val_loss: 10.6874 - val_accuracy: 0.3576\n",
      "Epoch 137/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0473 - accuracy: 0.9851 - val_loss: 10.3752 - val_accuracy: 0.3504\n",
      "Epoch 138/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0403 - accuracy: 0.9872 - val_loss: 10.1212 - val_accuracy: 0.3584\n",
      "Epoch 139/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0236 - accuracy: 0.9927 - val_loss: 10.6494 - val_accuracy: 0.3628\n",
      "Epoch 140/200\n",
      "47500/47500 [==============================] - 10s 217us/step - loss: 0.0292 - accuracy: 0.9912 - val_loss: 10.3457 - val_accuracy: 0.3556\n",
      "Epoch 141/200\n",
      "47500/47500 [==============================] - 10s 217us/step - loss: 0.0258 - accuracy: 0.9924 - val_loss: 10.8291 - val_accuracy: 0.3540\n",
      "Epoch 142/200\n",
      "47500/47500 [==============================] - 10s 217us/step - loss: 0.0264 - accuracy: 0.9918 - val_loss: 10.9039 - val_accuracy: 0.3676\n",
      "Epoch 143/200\n",
      "47500/47500 [==============================] - 10s 217us/step - loss: 0.0213 - accuracy: 0.9937 - val_loss: 10.5587 - val_accuracy: 0.3636\n",
      "Epoch 144/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0268 - accuracy: 0.9919 - val_loss: 10.5817 - val_accuracy: 0.3740\n",
      "Epoch 145/200\n",
      "47500/47500 [==============================] - 10s 217us/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 10.8006 - val_accuracy: 0.3728\n",
      "Epoch 146/200\n",
      "47500/47500 [==============================] - 10s 217us/step - loss: 0.0167 - accuracy: 0.9951 - val_loss: 10.6139 - val_accuracy: 0.3700\n",
      "Epoch 147/200\n",
      "47500/47500 [==============================] - 10s 217us/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 10.3754 - val_accuracy: 0.3672\n",
      "Epoch 148/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0201 - accuracy: 0.9938 - val_loss: 10.6753 - val_accuracy: 0.3684\n",
      "Epoch 149/200\n",
      "47500/47500 [==============================] - 10s 217us/step - loss: 0.0165 - accuracy: 0.9955 - val_loss: 10.6502 - val_accuracy: 0.3584\n",
      "Epoch 150/200\n",
      "47500/47500 [==============================] - 10s 218us/step - loss: 0.0098 - accuracy: 0.9973 - val_loss: 10.6876 - val_accuracy: 0.3608\n",
      "Epoch 151/200\n",
      "47500/47500 [==============================] - 10s 218us/step - loss: 0.0089 - accuracy: 0.9975 - val_loss: 10.9305 - val_accuracy: 0.3668\n",
      "Epoch 152/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 11.0547 - val_accuracy: 0.3708\n",
      "Epoch 153/200\n",
      "47500/47500 [==============================] - 10s 217us/step - loss: 0.0054 - accuracy: 0.9989 - val_loss: 10.6883 - val_accuracy: 0.3708\n",
      "Epoch 154/200\n",
      "47500/47500 [==============================] - 10s 217us/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 11.1362 - val_accuracy: 0.3648\n",
      "Epoch 155/200\n",
      "47500/47500 [==============================] - 10s 217us/step - loss: 0.0077 - accuracy: 0.9978 - val_loss: 10.8087 - val_accuracy: 0.3632\n",
      "Epoch 156/200\n",
      "47500/47500 [==============================] - 10s 217us/step - loss: 0.0086 - accuracy: 0.9979 - val_loss: 10.8350 - val_accuracy: 0.3772\n",
      "Epoch 157/200\n",
      "47500/47500 [==============================] - 10s 218us/step - loss: 0.0079 - accuracy: 0.9980 - val_loss: 11.0107 - val_accuracy: 0.3628\n",
      "Epoch 158/200\n",
      "47500/47500 [==============================] - 10s 217us/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 11.0200 - val_accuracy: 0.3604\n",
      "Epoch 159/200\n",
      "47500/47500 [==============================] - 10s 217us/step - loss: 0.0152 - accuracy: 0.9956 - val_loss: 11.5117 - val_accuracy: 0.3688\n",
      "Epoch 160/200\n",
      "47500/47500 [==============================] - 10s 218us/step - loss: 0.0276 - accuracy: 0.9920 - val_loss: 11.1126 - val_accuracy: 0.3648\n",
      "Epoch 161/200\n",
      "47500/47500 [==============================] - 10s 217us/step - loss: 0.0234 - accuracy: 0.9931 - val_loss: 10.8519 - val_accuracy: 0.3680\n",
      "Epoch 162/200\n",
      "47500/47500 [==============================] - 10s 217us/step - loss: 0.0142 - accuracy: 0.9954 - val_loss: 11.6399 - val_accuracy: 0.3584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0220 - accuracy: 0.9927 - val_loss: 11.1928 - val_accuracy: 0.3636\n",
      "Epoch 164/200\n",
      "47500/47500 [==============================] - 10s 216us/step - loss: 0.0206 - accuracy: 0.9935 - val_loss: 11.1937 - val_accuracy: 0.3616\n",
      "Epoch 165/200\n",
      "47500/47500 [==============================] - 10s 215us/step - loss: 0.0206 - accuracy: 0.9937 - val_loss: 11.5323 - val_accuracy: 0.3576\n",
      "Epoch 166/200\n",
      "47500/47500 [==============================] - 10s 211us/step - loss: 0.0260 - accuracy: 0.9920 - val_loss: 11.0635 - val_accuracy: 0.3644\n",
      "Epoch 167/200\n",
      "47500/47500 [==============================] - 10s 211us/step - loss: 0.0523 - accuracy: 0.9840 - val_loss: 10.9755 - val_accuracy: 0.3504\n",
      "Epoch 168/200\n",
      "47500/47500 [==============================] - 10s 211us/step - loss: 0.0532 - accuracy: 0.9840 - val_loss: 10.9130 - val_accuracy: 0.3536\n",
      "Epoch 169/200\n",
      "47500/47500 [==============================] - 10s 213us/step - loss: 0.0519 - accuracy: 0.9840 - val_loss: 10.3251 - val_accuracy: 0.3572\n",
      "Epoch 170/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.0412 - accuracy: 0.9875 - val_loss: 10.5071 - val_accuracy: 0.3604\n",
      "Epoch 171/200\n",
      "47500/47500 [==============================] - 10s 211us/step - loss: 0.0506 - accuracy: 0.9852 - val_loss: 10.8255 - val_accuracy: 0.3500\n",
      "Epoch 172/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.0565 - accuracy: 0.9830 - val_loss: 10.5072 - val_accuracy: 0.3572\n",
      "Epoch 173/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.0597 - accuracy: 0.9820 - val_loss: 10.4412 - val_accuracy: 0.3568\n",
      "Epoch 174/200\n",
      "47500/47500 [==============================] - 10s 211us/step - loss: 0.0301 - accuracy: 0.9904 - val_loss: 10.6206 - val_accuracy: 0.3664\n",
      "Epoch 175/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.0355 - accuracy: 0.9895 - val_loss: 11.0638 - val_accuracy: 0.3696\n",
      "Epoch 176/200\n",
      "47500/47500 [==============================] - 10s 211us/step - loss: 0.0211 - accuracy: 0.9934 - val_loss: 10.9706 - val_accuracy: 0.3620\n",
      "Epoch 177/200\n",
      "47500/47500 [==============================] - 10s 213us/step - loss: 0.0250 - accuracy: 0.9919 - val_loss: 11.2256 - val_accuracy: 0.3644\n",
      "Epoch 178/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.0223 - accuracy: 0.9929 - val_loss: 10.8830 - val_accuracy: 0.3692\n",
      "Epoch 179/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.0211 - accuracy: 0.9931 - val_loss: 11.2145 - val_accuracy: 0.3592\n",
      "Epoch 180/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.0273 - accuracy: 0.9919 - val_loss: 10.9759 - val_accuracy: 0.3632\n",
      "Epoch 181/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.0190 - accuracy: 0.9940 - val_loss: 11.3495 - val_accuracy: 0.3688\n",
      "Epoch 182/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 11.4676 - val_accuracy: 0.3632\n",
      "Epoch 183/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.0182 - accuracy: 0.9943 - val_loss: 11.7425 - val_accuracy: 0.3624\n",
      "Epoch 184/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.0341 - accuracy: 0.9901 - val_loss: 11.4487 - val_accuracy: 0.3584\n",
      "Epoch 185/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.0289 - accuracy: 0.9907 - val_loss: 11.0568 - val_accuracy: 0.3500\n",
      "Epoch 186/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.0343 - accuracy: 0.9900 - val_loss: 12.0006 - val_accuracy: 0.3428\n",
      "Epoch 187/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.0363 - accuracy: 0.9891 - val_loss: 11.3369 - val_accuracy: 0.3588\n",
      "Epoch 188/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.0311 - accuracy: 0.9908 - val_loss: 11.4183 - val_accuracy: 0.3628\n",
      "Epoch 189/200\n",
      "47500/47500 [==============================] - 10s 211us/step - loss: 0.0345 - accuracy: 0.9900 - val_loss: 10.8615 - val_accuracy: 0.3652\n",
      "Epoch 190/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.0265 - accuracy: 0.9921 - val_loss: 11.0774 - val_accuracy: 0.3624\n",
      "Epoch 191/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.0217 - accuracy: 0.9934 - val_loss: 11.4402 - val_accuracy: 0.3488\n",
      "Epoch 192/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.0203 - accuracy: 0.9938 - val_loss: 11.7419 - val_accuracy: 0.3640\n",
      "Epoch 193/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.0211 - accuracy: 0.9939 - val_loss: 11.3961 - val_accuracy: 0.3644\n",
      "Epoch 194/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.0375 - accuracy: 0.9885 - val_loss: 11.5913 - val_accuracy: 0.3492\n",
      "Epoch 195/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.0449 - accuracy: 0.9867 - val_loss: 11.2508 - val_accuracy: 0.3616\n",
      "Epoch 196/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.0378 - accuracy: 0.9885 - val_loss: 11.2317 - val_accuracy: 0.3632\n",
      "Epoch 197/200\n",
      "47500/47500 [==============================] - 10s 211us/step - loss: 0.0316 - accuracy: 0.9907 - val_loss: 11.2710 - val_accuracy: 0.3620\n",
      "Epoch 198/200\n",
      "47500/47500 [==============================] - 10s 211us/step - loss: 0.0250 - accuracy: 0.9922 - val_loss: 11.0930 - val_accuracy: 0.3560\n",
      "Epoch 199/200\n",
      "47500/47500 [==============================] - 10s 213us/step - loss: 0.0308 - accuracy: 0.9905 - val_loss: 11.2250 - val_accuracy: 0.3604\n",
      "Epoch 200/200\n",
      "47500/47500 [==============================] - 10s 212us/step - loss: 0.0199 - accuracy: 0.9937 - val_loss: 11.0407 - val_accuracy: 0.3608\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "baseline_history = baseline_model.fit(X_train, y_train,\n",
    "                                batch_size=batch_size,\n",
    "                                epochs=epochs,\n",
    "                                validation_data=(X_dev, y_dev),\n",
    "                                workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nOydd5gV1fnHP+8t2ztLZ2HpiPSmiCIqKoKKGjWaaDT60xhFo8YkamxpakxiYmI3GnsLKkHBrmChLggICEjdXZa2ve9t5/fHmS3A7rILu1x2eT/Pc59778yZc945M/Odd95TRowxKIqiKG0fV7gNUBRFUVoGFXRFUZR2ggq6oihKO0EFXVEUpZ2ggq4oitJOUEFXFEVpJ6igK4qitBNU0JWDQkR+JCIZIlIqIjtE5H0ROTGM9jwvIj7HnurPyiZue5+IvNzaNjYVEdkqIpPDbYfS9lBBV5qNiNwK/AO4H+gM9AQeB6Y3kN5zmEx7yBgTV+czvCUyFYteK8oRj56kSrMQkUTg98ANxpi3jTFlxhi/MeZdY8yvnDT3ichMEXlZRIqBK0UkUkT+ISI5zucfIhLppE8VkfdEpFBE8kXky2oBFZHfiMh2ESkRkfUictpB2JwuIkZErhCRTBHJFZHfOuumAHcCP6zr1YvIPBH5k4h8DZQDfUSkm4jMdmzcKCLX1Cmjep/fcGxdLiLDnXW/EpG39rHpXyLyj4PYl2ucsvMdW7o5y0VE/i4iu0WkSERWicgQZ91UEVnr2LVdRG5rbrlKG8EYox/9NPkDTAECgKeRNPcBfuA8rNMQjb0JLAI6AR2BBcAfnPQPAE8CXudzEiDAQCAL6OakSwf6NlDm88AfG1iXDhjgGceW4UAVcEwde1/eZ5t5QCZwLOBx7JqPfRKJAkYAe4DT9tnnC520twFbnN9dgTIgyUnrAXYDoxuwdyswuZ7lpwK5wCggEvgX8IWz7kxgGZDk1N0xQFdn3Q7gJOd3MjAq3OeRflrnox660lw6ALnGmMAB0i00xswyxoSMMRXAj4HfG2N2G2P2AL8DLnfS+rGi18tYb/9LY4wBgljhGiwiXmPMVmPMpkbKvM3x8qs/L+yz/nfGmApjzEpgJVbYG+N5Y8waZ1+7ACcCvzHGVBpjVgD/rrMPAMuMMTONMX7gYazwH2+M2QF8AVzkpJuCrcNlByh/X34MPGeMWW6MqQLuAMaLSDq2DuOBQYAYY75zysVZN1hEEowxBcaY5c0sV2kjqKArzSUPSG1CXDxrn//dgG11/m9zlgH8BdgIfCQim0XkdgBjzEbgZqz3u1tEXq8OMTTAX40xSXU+V+yzfmed3+VAXDP2oRuQb4wp2WcfuteX3hgTArLr7OMLwGXO78uAlw5Qdn3sVYfGmFLs8ehujPkMeBR4DNglIk+LSIKT9AfAVGCbiMwXkfEHUbbSBlBBV5rLQqASG05pjH2n8cwBetX539NZhjGmxBjzS2NMH+Ac4NbqWLkx5lVjzInOtgb486HvwgFtrW95DpAiIvF1lvUEttf5n1b9w2kD6OFsBzALGObEtc8GXjkIO/eqQxGJxT4xbQcwxvzTGDMaGyYaAPzKWb7UGDMdG+6aBbx5EGUrbQAVdKVZGGOKgHuAx0TkPBGJERGviJwlIg81sulrwF0i0lFEUp08XgYQkbNFpJ+ICFCMDbUERWSgiJzqNJ5WAhXOupZmF5DeWE8WY0wWNu7/gIhEicgw4Gr2FubRInKB8/RyMzZOv8jZvhKYCbwKLDHGZB7AJq9TTvXH42z7UxEZ4dTJ/cBiY8xWERkrIseJiBcbr6/E1mGEiPxYRBKdUFB1/SrtEBV0pdkYYx4GbgXuwjYMZgEzsN5fQ/wRyABWAd8Cy51lAP2BT4BS7BPA48aYedj4+YPYhsCdWA/zzkbK+LXs3Q89t4m79F/nO09EGosvX4ptYM0B3gHuNcZ8XGf9/4AfAgXY2PoFjohW8wIwlKaFW+Zib2DVn/uMMZ8CdwNvYRs6+wKXOOkTsI2+BdiwTB7wV2fd5cBWp8fRddSGfpR2hti2J0VRDgURuQ/oZ4xpUCxFpCewDuhijCk+XLYpRw/qoSvKYcAJ59wKvK5irrQWh2sEn6IctTiNl7uwoZApYTZHacdoyEVRFKWdoCEXRVGUdkLYQi6pqakmPT09XMUriqK0SZYtW5ZrjOlY37qwCXp6ejoZGRnhKl5RFKVNIiLbGlqnIRdFUZR2ggq6oihKO0EFXVEUpT6yZsHnZ0Go7cyUoIKuKIpSH9tehR0fQN7icFvSZFTQFUU5MqjYceA0rUXpZpgzFLa9Ubssd5H9zv5fw9vt+AjmDoPi71vXviaigq4oyuGncg/4Cmv/5y+Hd7pB1tu1y8oyIb+57wA5CII++OoSKFoNi6+B0q325lKeBQhsn13/dlX5sOhKKPwWlt0Ee762IZrSLa1vcwOooCuKcngxIfhkohW/6pHqOXPt95oH7LKQH+ZNg08mga+o9Wwp2wZfXQj5S2HU3+2yRT+t9c7TfwTF62DTs7DxmVp7AZb9wt6Y+l5tQzOfnmq/M25sPXsPgM7loijK4WXnJ1YkAXLmQPezYddnIG7Iz4Dd86HgG+sxA2z+Dwy6+dDKDPnB5bW/jQERKF4PH4y2N5hRD9sy3FGw9OfgL7bph9wLW1+Bxf9nt00eAR3Gwp4FsPVlOPYuGHqPfZIwIeg2FdY+CN8/CanjbRmxPSH1+NoblTvi0PalEcI2l8uYMWOMDixSlHaKvxTylkCXU/dfN3865C4Ebzx4E+H0r2BmivV0M/8LJgCBcuh8KgSKbfjj7A3gch+cLVtegaXXwcmzwRMPX15gvfGtL9uby9SVENfHpg354b1joHQTpIyFKUusdy4eWPIz6HcNjH4EPhoP5dlwzgbwxEKwyqYhZG8Shd/WMUDg2DvtzasqFybNhaShB7cvgIgsM8aMqW+deuiKohw6wUpY+xfreY9/HpbfApv+DSe/B92n2TTZ71ohz3kPBt8O8QNsDHrhFRCqgm7ToMvpkPkGeOJg6L029PHVRbDkGhh0KyQea73rA5G/HJZca/Nb/w9r39IbwB1tY+MLfgQhHwz7Q62Yg/XKh/0eFvwYUo+zy/pebb9z5sK21yAmzd6sjn/eijmAO9LJwA2nf217xlTl27zX/Ml+orsCAh+fZG8unSYecrXviwq6oiiW/OU2vJAyFtIvOXD6aip321h38Xf2f3w/2PKi/Z1xAySPhA3/sqEIcUFUV+h3HcR0t42gWTOtd9vpJOu1p9V5XW2P86D/z62XvPk/EN8fTngVOtRxUOuGU6pZdS8UrrKhkJg0e3OoDpuMeRS++5sV9EG37L8/vS6BwtU2fl6X3j+BzDdhxW+gx3TofXn99eGNhy6Ta/+fONPexDqdDP4imH+OvcG0AhpyUZSjBROyglofWbPgy/Ptb3c0nL3Oxn73LISM62HofVbE9iVYaRsDC1bASW9b0d49HxA47llYfFVt2n4/s2LqquNH+grhw3EQ0wNO+6xh2yt3Q9ZbsOpu6DgRJjq9YdY+BN/9Bc5YBPF97bKitTDnWBj6O0j7AUQkQXQ3WHw1hAIw/gUbIw9WQHSXptZebTgmvh9M/F8dr7yZhIIHHz6i8ZCLCrqiHA2E/DC7n/Uqhzuvci1YaUMB456B+dOgYhecNNPGh7tOsQL89SXWqxRHoPtcCct/CZuftyGEskwIlMCJ/4WeF1qP+IMx0ON8K7pbXoHKnZA0zHqt9YVL/MW2wTAi8cD7sexm2+B4wS6o2A7vj7D71mUynPKRTbPgMsieBedlQmSHlqpBS7ASXJFNC/u0EhpDV5S2hr8YvAktl9/uL6E8E9Y+AN3PhdRx1pvO/K/1fvd8bRsKk4fD4Dvg23sg+x2I7m4bLZffaj3cou9g3cPQ+RRrX6dJtmdH96m2nJTRcMqHtY1+vX98YNuas5+9LoX1j9gGzS0v2UbOgb+Ab++1vVNMwI7wHHx7y4s52F4wRzDqoSvKkcamZ604TZpbG4vd/DxEJNeGPYrW2Ua/0f+AlFEHzrPas41MtSGIUz6E2X2tV1y5G9wxcP52uy7kt0LvTbTd7SI7QKDMNuYVfAOJg2HKsvCImzHwbj87slNcMOF1G1ZZdJWN/5sADP4NDL+/4fBSG6cxD73Zeywiz4nIbhFZXWdZioh8LCLfO9/Jh2Kwohyx1B3duC/G1A48KdkEBatq15VlwhfnweYX9h6cUk3uElg6w3Z/W/+IFdWvL4WyLPAVWIFfeoONv4YCsPAnsOdLK2QhPxRvsF0F/SWQ86EV4Lp2Zc+2N4fjnrUx5o/G254lE9+13vYxv7JiDraBMf1HtndKtZfribU9Vnr+EE54LXyeqgj0/T8b5z/pHeh5kRXu8c/DD3bDtLUw4sF2K+YHotkeuohMBEqBF40xQ5xlDwH5xpgHReR2INkY85vG8lEPXWlzfPNrK7ZnLNzfK/Y5vRdCfus1z59mxffcTVCVB5+dZvstY6DXj+CEl2pFJ1AOc4ZA2Rbofg5sfxeOuQ2+f8qWk3aBHZUIMOl9G6dedRf0uQo2PwexveyIR3HbT8hnQyGT5oAnBgrXwNwhMPZJ6P8zWP0nu33yKDjrMAytb2mMgWB5bZfBo4wWjaEbY74QkfR9Fk8HJjm/XwDmAY0KuqK0Kba+bntTgB3affpXtQ1j/hL4fIod5Shu+Oh48CbZxsRvbrOjIIOVMGWp7Yu9+nc21uyJhe3vASEr5h2Os2LuiYMh99h+2kuuhbyldoRieRasuN2OoOx1KRz/rM03dyGM/Kt9eghV2bDKitvh8zNt+GH9v6yd3c+238feaW8mnU4+7NXYIogctWJ+IFqqUbSzMWYHgDFmh4h0qi+RiFwLXAvQs2fPFipaUVqZsiw7sKXjBEi/zIY/tr5qG/xMCBZebucCOfG/Ns79zW12KPmm52zfaXc0TP7CinjyKChcadNgbE+Rih22R8mwP1hPuufFti9z3/+z5eyeB/2vt32jN/wTEgbCuKesbRNeqd/m6K42bj7/HFv+6Edsv2+wgnjsHYej5pTDjTGm2R8gHVhd53/hPusLDpTH6NGjjaIcUfjLjfnmdmP2LNp7+fzzjHk92piSLcaEgsbMGWbM3JF23cp7jXkFY9Y9sn9+pduMeX+MMVn/23t5xR5jPhxvzKrf2fwqdhkT9Nt1viJjgr7atCVbjFk6wxh/mTHFG4359HRjClY3cX9Kjdk205jSrU1Lr7QJgAzTgK4eVC8XJ+TynqmNoa8HJhnrnXcF5hljBjaWh8bQlYPGXwzu2EManAHArs/tVKl9f2qnUP3yfDu82xNne4F0PMF6yAt+DCP+DIN/bbdb/y87XeqkD+CLcyHtQjjh5bD2TVaOHlq0l0sDzAaucH5fATQyI7yiHAL+EpjdB+YOhZ2f7r/emMbno67c48x3vRO+/IGNUVfusY2EOXNtd7forrYRc9HVdp6RjifuPUS816W2J8jXPwQThOF/UDFXjggOptvia8BCYKCIZIvI1cCDwOki8j1wuvNfUVqebW/YXiP+Itvot694b33ZCv7mF/bftirfNli+NwA+mwyBUttv+fsn7afXpTa2PPkL6HGB7UGSMsb2Fqk7V0hUqp1Iyl9kt6k7uZOihJGD6eVyaQOrTjtEWxRlf0zI9s32RNv/m/5tZ9w75QP4X7oV4pF/rk2/5SX7vfTntdOzVuTYftmZ/7U9RbqeZd9CM+IhO9nS6t9ZT3ugM+d2dBfb2Dj0Hjuxkydmf7sG3GCfEI69s1V3X1Gagw79V45sFl5p55E+5UM7mCVvse1BEtPDDmHf/CwMvMnO9Jc4FHZ9Cn2vsbPbffmDvfMSF4x9Cvr9nx3oUy3WGRn2ZQSp4/ZOn9BIM1CXyXBRkYZalCMKFXTlyMGEoHKXDZcESq1ob33Jdrv79BSbxh0F6c60pQOut/ON/C/dhk6SR9k8Bt4EIx6w3fwwdqY9bzyI14ZLwM4kCHZE5Man7JtpmouKuXKEoYKuhAdjoGyrHVruibcTP23+T+16cVlxThkLJ75hX4QQ1w8GzKgV5c6nQrez7SATd6SdgzvxWEga4qxvwsCZiGSYuurA6RSlDaCCrhw8gXKYNxX6/BT6XFG7vL55t/3FdtKptAshd4EdRl+eCVGd7ZSsm/9jPe/kYVakXR4bL+97DcT1hsnz9y9fXDDp3doyE46xL1NQlKMUnW1ROXg2vwiLrgBXhH3tVvIIyJhhGxzPzLBhk+oX6X73F9s1UNy2ATJlrA13rHvYNlR2PgVO/eSonVRJUZqKzoeutA6bnrFd9kJ+2287qguUbLCi/M1tULTGvgYsYZB9F2PKaDtpVHQX26PE5bFTn373VztoR8VcUQ4JFXSleez+ApbdYt/puOcr2/Wv21RY91c7YGfwb6yor3W6EkYk24miyrNgzGO2IbMusWkw5pHDvhuK0h5RQVeazubnbeNlZEfYuNy+2Lf3TyC6Mxxfp0HTX2L7fHc53b65JmOGDbX0vDBspivK0YAKurI/xkDxeiheZ6dcdXnswJxvboPUE+ybdEo2gi/fivm+eOPtS4ZdXivuK39r33wTVe8knIqitBAq6Eczu7+C75+AguVw0lv21WJgXwyc+ab9PfT3MPRu2Pi0HXI/4iEr2CkH6E1SPVTeG2+H0rfG+x0VRdkLFfSjBROC8u02Zm0MrPu79birXzv2xflw5hLbkJn5pp1/u2K7fSt8ykjbS6XzKdBxfPPLTh7WsvuiKEq9qKAfLay6F9beb19htmeBnb8k7QIY/6J9pdmnp9nJrsRlY+QjH7KvVZtzjH1JgicWhv0p3HuhKEojqKAfDQTK4fvHrJf+5QU2Ht7nSvvCYHFBp4kw4TVYfA34C2HkX6yAe2JhwhvWa+/zU4hMCfeeKIrSCCro7ZmqPCj4Boq+s2+OP/55WH4rdJkA457eu993zwttg2fW23byqmq6TbEfRVGOeFTQ2yuVu+GTSXYWQrDzevf+CaSdb9/IU98gnphuMHDGYTVTUZSWQwW9vRCstA2dJmh/b3vNvnx49CM2Rt7nKjs7oDch3JYqitJKqKC3VSr3WOGOTbMx8i+mw85P7Dpx2blSjnuuaTMOKorSLlBBb6ssvALyl8KU5bD0Otj1mY2R97zYeuneuHBbqCjKYUYFvS0SrITdn9vvD0baxs+xT+w9ha2iKEcdOr1dWyR3oRXznhdbMe/3M+h/XbitUhQlzKiHfqRjQhAK2N87P4LorvblxOKG456BIXfbFzsoinLUo4J+JGFCULrFzjEuAoVr4Mvz7URY7kjrlXvi7Vt+OoyzPVaqX7emKMpRjwr6kcT6R+zAn4RBENsL9nxt+4wf+1sIlECH42HZjVC6EXpdEm5rFUU5wlBBP1II+e3r2BKHQGSqjY33mA4jHoSYHrXpolLhy4sg7bzw2aooyhGJCvqRwrY3oTwbTn4Suk9rOF2XyXBhvg3JKIqi1EEFPZwYAxses2+3L9tmQy3dzjrwdirmiqLUgwp6ODAhyHkfvn8ccubaBs7Op9j3beqLkhVFOUhU0MPBt7+385FHJMPIv8KgW1TIFUU5ZFpU0EVkK1ACBIGAMWZMS+bfLgj5YeOT0PVMmDgb3BHhtkhRlHZCa3jopxhjclsh3/ZBzgdQuQv6/1zFXFGUFkWf8w83m5+zA4O6TQ23JYqitDNaWtAN8JGILBORa/ddKSLXikiGiGTs2bOnhYs+wjEGvn8Cts+2L5pwecNtkaIo7YyWDrlMMMbkiEgn4GMRWWeM+aJ6pTHmaeBpgDFjxpgWLvvIIxSErLdszLxkI5RnQbdpMOSucFumKEo7pEUF3RiT43zvFpF3gHHAF41v1Y5Z9FPY+hLE9YNOk6DDWOh/Pbjc4bZMUZR2SIsJuojEAi5jTInz+wzg9y2Vf138QT9e9xEestj9hRXzQb+EEX9WEVcUpdVpyRh6Z+ArEVkJLAHmGGM+aMH8AXh86eP0fqQ3VYGqls665Qj5IeMmiEmDYb9XMVcU5bDQYh66MWYzMLyl8muIfin92F6ynXc3vMuFgy9s7eKaT6ACvroIClfCiTPBExNuixRFOUpoc90WT+s+hus6JvPCyhfCbcr++Ith3ll2OP/YJ6HnD8JtkaIoRxFtbui/e8M/eCypgBMy57KrdBed4zqH2yTY/SVkz7JvEipaAye8AumXhtsqRVGOMtqch84xtxGKSOWRjiFeXPF8uK2BsiyYNxU2PAq+Apj4joq5oihhoe0JujcBz+iHOS4Kslf8gcLKwvDZYgxkzAAThLPXwXnboPvZ4bNHUZSjmrYn6ADpl1GaNJrfJ5bx6Ge/Co8Nlbm2n/n22TD0dxDXOzx2KIqiOLRNQRchbuJMItxeTt7xb5Zu/ezwll+VDx8dD1tfgcF32OlvFUVRwkzbFHSAuHSCY/7FhCjo9uUZ5G996/CU6yuAry+xw/hP+xxG3A+uNte2rChKO6TtCjoQN+BnbBrzAiXBEPFfX0TZ98+0XmFF38HHJ8HMFNj5MYx9Ajqd2HrlKYqiNJM2LegA/Qf+hMzjXmdBJcQuvZbKhVeDv6TlCvAVwIo74f2RUPwdDP09nL4A+l7VcmUoiqK0AG1e0AHOOOZiCo9/jX8UuojY/BzBd7rB4muhaN2hZbx9Lrw7ANY+AGkXwNQ1MPRu6Di+ZQxXFEVpQdqFoANMP/aHjJ42jzN3J/BmkY/glhdhzmCYdzZseg4K10DFLijdarsb1sVXBN/+AXIX2Slvt70Bn58F86dBdDc46xuY8CpEHwGDmBRFURpAzL7idpgYM2aMycjIaPF8N+ZvZNqr0ygp2sxbwydyfGAjUp65d6LkUdDvGojqAiXrYf2/oGI7ILb7YelmiOkJfa6EY+8Ad1SL26koinIwiMiyht7X3O66Z/RL6ceiqxdx9eyrOWHZO5zYcwKvnvYkacE88BdBKGBHdS79ee1GyaPghJcgcybkZ8CwP0Gvi0HazQOMoihHAe3OQ6/GGMPLq15mxvszCIaC/PHUPzJj3Aw8Lo8Nq5RnQdUeiO0NUamtZoeiKEpL0piH3m5dUBHh8uGXs/rnq5nYayK3fHgLY58Zy+LsxXZ+8rh0+wYhFXNFUdoJ7VbQq0lLTGPOj+Yw86KZ7C7bzfhnx3P9nOvDOweMoihKK9DuBR2st/6DwT/guxu+4xfH/YKnlj1F/3/15/GljxMIBcJtnqIoSotwVAh6NQmRCfx9yt/JuCaDYzseyw1zb2DoE0N5b8N7hKstQVEUpaU4qgS9mpFdR/L5FZ8z64ezCJkQ57x2DpNfmsyKnSvCbZqiKMpBc1QKOtgwzPRB01n989X8c8o/WblzJaOeGsVP//dTthdvD7d5iqIozeaoFfRqvG4vNx53Ixtv2shtJ9zGq9++Sv9/9eeez++h1FcabvMURVGazFEv6NUkRSXx0OkPse6GdZw78Fz+8MUf6P+v/vx7+b8JhoLhNk9RFOWAqKDvQ+/k3rx+4essvHohvZN6c82713Ds48fy8qqXtUeMoihHNCroDXB8j+P5+qqveevit4j0RHL5O5cz6NFB/Oeb/+AP+sNtnqIoyn6ooDeCiHDBMRfwzc++YdYPZ5EYlchVs69iwKMDeGTRI5RUteC864qiKIeICnoTcImL6YOmk3FNBu9d+h7d4rtx84c3k/b3NH798a/JLs4Ot4mKoijtd3Ku1mZx9mIeXvQwM9fOxCUupvafyln9zuLMvmfSO7l3uM1TFKWd0tjkXCroh8jWwq08uuRRZq6dybaibQD0Se7DST1PYlr/aZza+1RSolMQkTBbqihKe0AF/TBgjGFD3gY+2PgB87bN44ttX5BfkQ9AhDuCzrGd6ZfSj3MHnsvgjoPpFt+NgR0G4nV7w2y5oihticMi6CIyBXgEcAP/NsY82Fj69ibo+xIIBfg682uW71jOrrJd7CrbRUZOBqt3r65J43V56RTbiaSoJBKjEukS14XU6FQqAhV4Xd6a5UlRScRFxFEVqLI3h7jOdIrtRIw3Bn/QT5e4LnSO64xLX8ihKO2eVhd0EXEDG4DTgWxgKXCpMWZtQ9u0d0FviG2F28guziazKJNVu1axu2w3hVWFFFYWsrN0J7nluUR7ogmEAhRWFlLmL2tSvi5xEeuNxWBwi5vUmFQiPZG4xLXfJ9IdSaQnkgp/BeX+coImSI+EHsRHxBMyIYImSDAUrPmOi4ijV2IvRARBiI+Mp8JfQUWgAo/Lg8flQRD8IT++oI8KfwXFvmKSIpNIS0wDqMkvEAoQ7YmmQ0wHUmNSCZkQ+RX5RHuiMRgKKgooqCygwl9Rr+0iUu/ykAlRVFmES1wkRCbUfOIi4uq90YVMiKKqIvIr8imsLCTKE0ViZCKJUYkYY/AFffiCPrxuL3ERccR6Y4mLiMPj8pBbnos/5CfKE0WkO5IYbwzxkfHER8Tjdrmp8FdQGaikMlCJL+gj2huNx+WpqW9f0FdTl9X7EzKhvercYIj1xhIfGU+MNwavy1tzjkR6IgmZEMVVxQiC2+WuOQ5uceN2uQmZEIFQgEAogMflIdIdSYQ7glJfKaW+UjwuDxHuCLxuL16Xt+Y7wh1h83G5a/Kq/naJC2Hv0KHb5cbr8uJxeWqOT/V+CULIhA754w/5yS7OZk/ZHkImhMHYb2P2++91e+md1Ju4iDhCJkRSVFJNfVWnr/6ISE29eFweDAZjzF751V3WEt8el4eEyAR6JPQgMSrxoDTkcAj6eOA+Y8yZzv87AIwxDzS0zdEq6M3FH/RTXFVMia+EKE8UvqCPXaXW46/wW0HNKclhZ+lOSn2luMSFP+QnryIPX9C338URDAWpClZRFagi2htNjDcGQcgqzqLMV1bvhVxUWURmUWaN8FQ/QUR7owmGrEiHTIgIdwQR7ggiPZEkRCaQV55HXkXeXvvjFjdB0/jIW5e4agS+vgu8ISLcETVC1hwEwaCzbSqHj8emPsb1Y68/qG0PxztFuwNZdf5nA8fVY8i1wLUAPXv2bKGi2zdet5cOMR3oENOhZlnPxPDWXSAUwC3uJjX0VgWqcImrxsMD8AV95Ffkk1eeh4iQEp1CZWMWjuUAACAASURBVKASgOSoZOIj4xsNH9X1omq8LYRITyTGGKqCVfYmWFVCia+kwamRk6KSSIlOISEyAV/QR1FVEUWVRXt5br6gj1JfKWX+Msp8ZfiCPlJjUolwR9TcGMv8ZXuVFeWJqvl43V4q/BX4Q35ivbHW23Z79/LaQiZUU0dusd42UJNvmb+MQChAfEQ8XeO74g/6cYmL+Mh4gJqbavUTUDAUrPHa3eImEApQFazCF/TVeP2BUAB/0D5R+UN+/EF/zRNWdR77PqntezM1mJqy/SF/vV6tW9z1PlE15+N2uekW343OsZ33elKo+8RW/b8yUMmmgk01T3iFlYX4Q/7aJzxqn/BCJoQv6KMqWEUgFNjrianuU0ZLfvuDfkp8JYzqOurAF9pB0FKCXt+Vvd9VZIx5GngarIfeQmUrh5lqwWkKkZ7I/ZZFuCPoEteFLnFdDqr86gukPtEXkRox7RTbqVl2dvJ0atY2ypFHfGQ8HWM7htuMsNFSrWjZQFqd/z2AnBbKW1EURWkCLSXoS4H+ItJbRCKAS4DZLZS3oiiK0gRastviVOAf2G6Lzxlj/nSA9HuAbQdZXCqQe5DbtjZHqm1qV/NQu5rPkWpbe7OrlzGm3rhS2AYWHQoiktFQK2+4OVJtU7uah9rVfI5U244mu3QkiqIoSjtBBV1RFKWd0FYF/elwG9AIR6ptalfzULuaz5Fq21FjV5uMoSuHFxG5D+hnjLmslfJfA9xgjJkndrTSc8B5wPfAL7FzAw1s4TJ7AmuBRGMOMHRVUdoIbdVDV1oYEfmRiGSISKmI7BCR90XkxMNRtjHmWGPMPOfvidg5gXoYY8YZY75sCTEXka0iMrlOmZnGmLjWEnOxbBaRBuczUpSWRgVdQURuxXY5vR/oDPQEHgemh8GcXsBWY0zTZiU7cpkIdAL6iMjYw1mwiLTUCHClrWGMaVMfYAqwHtgI3B5GO9KAz4HvgDXAL5zl9wHbgRXOZ2oYbNsKfOuUn+EsSwE+xoYxPgaSneWJQClwUSP53Qe8XOf/f4GdQBHwBXBsnXVTsaGMEqcebnOWH+ekDwIB53OLk3fAOZ6ZgM9JUwr8DpgEZO9T728De4A84FFneV/gM2dZLvAKkOSsewkIARVOvr8G3sROT7HaSdMNeB/wOzasrVNH9zn1VuzYtgkYc4Bj8Jxjw9vVNtZZlwL8BzuaugCYVWfdJ44N1eVMAf7iLNsMvAMkOTa94+zTWmdf5jl1+EUTjlM08DfsWJAi4Ctn2Rzgxn3sXeXYtbu6vg50rgN3OMd0PXBmK5/vz9Vj2xt17NoKrHCWpzt1Vr3uycOsDw1dhwL806mzVcCogyr3cAhMC1aS2znJ+wARwEpgcJhs6Vpd6UA8dvrgwc5JfluY62krkLrPsodwboDA7cCfnd9TsILqaSS/+9hb0K9y9jkS69mvqLNuB3CS8zu5Th09ADwJeJ3t8rDe+H1APjDZSXcl8FWd/CbhCLpz/FcCfwdigSjgRGddP2yoJhLoiBWwf+xTJ5Pr/L+YvQV9PvANcBcwAiv8rzvrXsEK7FTgBKwQL2qkvmKw4j8V+AH2BhNRZ/0crOAkO/VxsrN8nFPuz4HV2EnvBgFnVNsP/Nn53IcV9NVYkTLAi069RDfhOD2GvQF0d+r1BCfdxcDiOumGO8fqVGAU+wv6fuc69jpY6eTXG3vNulvxfJ+4r237rP8bcI/zO72hdC1sU0P60NB1OBXrUAhwfN1j0JxPWwu5jAM2GmM2G2N8wOuEJyyAMWaHMWa587sEeyfuHg5bmsh04AXn9wvYRkeADkCuMabJc84aY54zxpQYY6qwF/VwEame3NkPDBaRBGNMQXUdOcu7YkX8ZGCdMaa5I4XHYT3pXxljyowxlcaYrxybNhpjPjbGVBlj9gAPO+U0xJLqHyKSho3dxwLPGmNWYL2+s5wkA4G1xpi5xpgFQBVW6BriAifNR8B72EnwpjlldXXyvc6pH78xZr6z3dXAM9gLG2PMdmPMOmPMR3XyXoSdK6k+7nPqpcLZvt7jJCIurNj/wikjaIxZ4KT7H3Yaj/5OnpcDbxhjPsPeeJvCdOzNsMoYswXrdY5r4rbNxhjzRUO2OY3sFwOvtVb5DdjUkD40dB1OB140lkVAknOuNIu2Juj1TdMbdhEVkXRgJLDYWTRDRFaJyHMikhwGkwzwkYgsc6YsBuhsjNkB9mTDxnfBel+pTY27iohbRB4UkU0iUoz1HMEOYwbrkU4FtonIfGeufLBhg41YkZvJ3kOeE4CnReQ5rHfbEGnAtvpuPiLSSUReF5Htjl0v17HpQHTDCkKn6jrChjGqbUlg78nmcoCoRursCuBNY0zAEcm3nWXV+5BvjCloYP82HcDWq3AE36E31uMH2/YBHPA4pWKfbvYry7H3TeAyR/gvxYasGqK+c/1Iuk5PAnYZY76vs6y3iHzjnJ8ntbYB++hDQ9dhi9RZWxP0Jk3TezgRkTjgLeBmY0wx8AQ2njsCG374WxjMmmCMGYX1BG8QkYmNpF0IVFLrKRyIH2G9icnY+Hu6s1wAjDFLjTHTsSfqLKw44HiKv8SGEILACSJyGra+soGfYevrkkbKzgJ6NiCkD2DPhWHGmATgMvY+Xxo7T3Kwsc269MTG3ZuFiPTAhicuE5GdIrITuBCYKiKpzj6kiEhSPZtnYc+d+ijD3hQC2BBQF2wsuCeO9w+8JCIJzu/GjlMu9pg3VNYLwI+B04ByY8zCBtI1dK4fSdfppeztne8AehpjRgK3Aq/WqbMWpx59aDBpPcuaXWdtTdCPqGl6RcSLPVivGGPeBjDG7HIeYUPYx+dWe9RsCGNMjvO9GxtnHQfsqn6Ec753O2mKgHuAx0TkPBGJERGviJwlIg/Vk308NpyQh/Vg769eISIRIvJjEUk0xvipbURERM4WkX7Ym8wqrDAFjTG7qs3G1lefRnZtCfaCfFBEYkUkSkQm1LGrFCgUke7Ar/bZdldDeRtjsoAFgBGRdBEZBlxTXUfOftR9cmhsIvfLsfHSgVihGwEMwJ67lzpe2fvA4yKS7NR19Q33WeCn2Hg2ItJdRAY564qw7R1XAKOxN4mQMabuK6E2O2VV10e9x8k5N58DHhaRbo43P15EIp31C7E3s7/RiHfeyLl+RFynzo3/Amx7BWCfQKrrzBizDPuUMqD+HA65/P30gQauQ1qoztqaoB8x0/Q6sblnge+MMQ/XWV437nU+ttHqcNoVKyLx1b+xDWqrsfVU/dh/BTZWCoBj/63YBsE9WE9xBtbD3pcXsT0jtmPDEov2WX85sNV5zL8O6ykD9Mf2lHgLGAo8buxAon3ra3tD+2Zsn/FzsA2gmdiL4IfO6t9hG8aKsCGIt/fZ/AHgLhEpFJHb6sn+UmzYZS32JvgVtZ7demz3QxGR47E9eBriCmffdtb9YBuEq+v/cmybwjrsBX2zs39LsIJ+N3AMtqG2l9gXsHd09jnH2ddXgUix7/Otph9W1OHAx+k2bE+opc5+/5m99eBF7HF6uaEdbeRcnw1cIiKRItIbe+yX7Lv9YWAytq0mu3qBiHSsrjMR6ePYtrmB7Q+ahvSBhq/D2cBP6pxjRXXCf03nYFpSw/nBxmc3YO+svw2jHSdivcpV1Om2hfVovnWWzwa6Hma7+mB7GKzEdpf6rbO8A/AptrvUp0BKGOosBusxJtZZFpb6wor1DqywZmMbJOutI+zj8GPOOfctB+iy2Ap2bcTeZPfqaodtr1jjHOvlwDktaMdP2Lu3UX12NXjsgN869bUeOOtwH0tn+fPYxue6aVutzvYppyF9aNVzTIf+K4qyFyISg+3T/7gx5sVw26M0nbYWclEUpRURkTOxYbdd2LCO0oZQD11RFKWdoB66oihKOyFsk/ikpqaa9PT0cBWvKIrSJlm2bFmuaeCdogcUdGf03tnAbmPMkHrWC/AItgW3HLjS1A73bpD09HQyMjIOlExRFEWpg4g0OGVGU0Iuz2MHNDTEWdi+nP2Ba7GjxxRFUZTDzAE9dGPMF85cBA1RM6kMsEhEkkSkqzmYTvGK0oYJGTtTgEvaV9NUcVUx0Z5ovG7vXsuNMeRX5JNXkUcwFCQxKhGXuFiXu47KQCUR7ggi3BF4XV48Lg+BUAB/yI/H5WFwx8EkRLbaiPujlpaIoTc0qcx+gu5MFHUtQM+ePfddrRxFGGPYUriFSHck3RO6Vw/GwEbwDkwwFKS4qpikqKR6twmZEIWVhRRXFVNUWUSUJ4peSb2o8FdQWFlIqa+UAR0GEOmJ3M+uuvlVi1Z+RT4ZORlsKdzCKemn0DelLwUVBSzfsZyMnAwydmSwfMdygqEgg1IH0Tu5Nz0TetIpthPr89bjC/qY2GsiXeO64hIX5f5yyv3lBEIB4iLiiI+MJz4ivua7zF/GJ5s/YUPeBnaW7mRn6U4Gpg5kxtgZBEIB3C43/VP6EwgFKPWVUuIroaSqhBJfCeX+cjrHdqZ7Qnci3BFsyt/ExvyNlPvLGdxxMGO7jyWrKIs5389hUfYiUqJTCJogJVUlRHmiKK4qZnfZbjrFdiKzKJOVu1YCkBiZSIeYDkR7oqkMVLK9ZDuVgcqDPQUY0GEAx6QeQ0FlAduLt5NbnkuvpF50ju1MZaCSykAlXreXHgk9uHTIpUwfOL3m2ARDQdbnrSfaE01aYhoel5Uyf9DPm2veJLs4G4NhUfYiyvxldIjugD/kp8JfQVWwyp43CDtKd7CzdCdlvjLiIuIY2XUkQzsNxRf0EemOJD4ynriIOAorCymoKCDGG0NxVTE5pTnklORQ6islEAoQDAXpm9KX8wedz8AO9gVbWcVZZBVlkVWcxc7SnSRHJeMP+flm5zfcceIdnDeoqdMnNZ0mdVt0PPT3GoihzwEeMM40piLyKfBrY+dJaJAxY8YYjaG3DYKhIJ9t+Yy4iDiCJsiKnStIS0gjNSaVlbtW4hY3Md4Yyvxl9Evpx/ge44mNiOXbXd/y+urXqQxUEjRBXOJiQIcBrMtdx1vfvUV2sR2RPazzMLKLs3GJi2n9p3FC2gn0Se5Dub+cN9e8yfq89fRL6cea3WvYmL+RDjEdyC3PtRe8y8uwzsOYlD6Jib0mkleexwebPuDjTR9TUFnfhIa1xHhjmJQ+iQlpE1i8fTGLsheRW55LjDeG1JhUkqOSySzKJK8ir9F8ojxRjOgygjFdx+B1e/ku9zu2FW4jsyiTMn8ZnWM743a5ySlp/nQmnWI70TWuKx1jO7IoexGlvtJm59EY/VP6U+orxe1yEx8RT1WwilhvLJ1iO7G7bDfJ0cmc3ud0jDHklueSV5FHRaCCCHcEPeJ70D2hO6kxqXhcHgorC/EH/RzT8RjiIuLwBX01n0AogMflwevyUhWsYsXOFSzbsYwNeRvoEN2B7gnd6RDdgS2FW8ivyCfaE02UJ4qqYBXrcteRU5JDakwqUZ4oAAoqCijz25daeV1e0pPS6RLXhezibLYUbqnZv34p/UiNSSWvPI8IdwQx3hi8bi9FlUWETIiu8V3pEteFWG8sRVVFLMxaSFZxFi5x1TxxVVO9zOvy0i2+G93iu5EYlYhb3LjERUZOBjtK9w9MRHmi6BzbmaKqIgBGdhnJL8f/kmkDpu2XtimIyDJjzJh617WAoD8FzDPGvOb8Xw9MOlDIRQW9dfEH/RgMXpcXg2H5juWsy11H76TeFFQWsKt0FxN6TqBnYk/W567nkcWPkFeRR5fYLqzZs4Zyfzm9knoxqssoPtj0AYuy950KpGE8Lg9DOw1l5a6VCEKUJwqPy4Mv6KsRg6n9p3JGnzMorCzk0y2f0ie5D2X+Mt7//v29hDgxMpFRXUexqWAT/VL6MazTMPIr8+kY05Fu8d3YWbqTJduXsCh7EVXBKgC6xnXlzH5nMrzzcBIjE0mMSqTMV0ZmUSYx3hiSo5OJcEewMGshH23+iA15G+iR0IMz+55J59jOVAQqasSrW1w3BnccTIeYDgzuOJjeSb35dMun5JbnEhcRx/DOwxnccfB+4Qiw3n2Zv4xYbywAWwu3UlhZSNAEifXGEuONwe1yWw/b8a5LqkpqRHtS+iS6J9TOoJpfkc/c7+fWeJub8jcR6YkkPiJ+Ly8/2hvNztKd7CjZQWWgkvSkdAamDiTaE83i7YtZs3sNaYlpTEibQO/k3gd1fh1OAqEAr69+nXlb59U8ycVFxDG622h8QR+b8jexqWATe8r34BY3Nx13E6f1Pg1/yE9SVH2TWjaMMYZAKIDX7cUf9FPqK6XUV0piVCIJkQlUBaqIcEc0+FS4atcqMosyAUhLSCMtMY0O0R2a/OTZFFpb0KdhJ3Kain3N2D+NMQecYVAFveUoqixi/rb5fLvrW3xBH+vy1jF7/WwqA5UIgsflwR/yN5pHXEQcvZN6s6N0B8ekHkNCZAKbCzazLncdKdEp/OX0v9ApthMhE2JElxFkFmVSUFnA8M7Da0II0d5oVu9ezfyt81mQvYBRXUZx98l3kxJtZ6Y1xpBVnFUjsvVhjGFzwWa2l2zHJS5Gdx1NtDf6gHVQGagkIyeDxMhEhnQa0qwLKLc8l5TolHYX+1baJ4ck6CLyGvY1YKnY4cD3Yl+bhTHmSafb4qPYnjDlwE+NMQdUahX0g2dzwWbeXf8u2cXZ+EN+/rPiPxRX1U61nBqTysWDL6Z7QveaWOSQTkMY3XU0mUWZJEUlkRydzJfbvqSgsoCkqCQuGnwRydH7v4ujuKoYr8vbJFFVFKX1OWQPvTVQQT8w63LX8c/F/yQjJ4PCykJGdxvN9uLtfJn5JQCR7kh8QR/nH3M+N427iTHdxhDjtdN2t+QjnqIoRw6NCXrYRooqe5Nbnsufv/oz7298n+FdhrO1cCsLshYQ6Y5kYq+JpCWmMX/rfOIi4njwtAe56NiL6JPcp6axSVEURZUgTBhjmL1+Nst2LGP5juV8vPljAqEAJ/c6mc+3fE6n2E7cf+r9XD3qajrFdmowHxVzRVGqUTUIA9sKt3Hzhzcza90sXOKiT3IfZoydwdWjrmZwx8HhNk9RlDaKCvphpLiqmPPfOJ/PtnyG1+Xlr6f/lZuOu6neLm+KoijNRQX9MGGM4dp3r2X+1vn88ZQ/8qOhP2oTfYAVRWk7qKC3MhX+Cj7d8imvr36dN9a8wQOnPcDtJ94ebrMURWmHqKC3Ig99/RC/m/87yv3lxEfEM2PsDH494dfhNktRlHaKCnor8eaaN/nNJ7/h7AFnc+O4G5mUPokId0S4zVIUpR2jgt4KvLv+Xa6cdSUnpJ3AzItm7jejn6IoSmugk1e0IMYYHvzqQaa/Pp3BHQfz9sVvq5grinLYUA+9hagMVHLV/67itdWvcemQS3n23Gd1/hNFUQ4rKugtQFWgigvfvJA538/h/lPv5/YTb9e5VBRFOeyooB8ixhiu/N+VzPl+Dk+d/RTXjr423CYpinKUojH0Q+SFlS/w+urX+dOpf1IxVxQlrKigHwJbC7dy4/s3cnKvk/nNhN+E2xxFUY5yVNAPgVs+vIWQCfHCeS/gdrnDbY6iKEc5KugHyYcbP2TWulncddJd9ErqFW5zFEVRVNAPhuKqYq6fez39Uvpx6/hbw22OoigKoL1cDoob5t7A1sKtzLting4cUhTliEE99Gby4soXeXnVy9x78r2c1OukcJujKIpSgwp6M9iQt4Hr51zPxF4T+e1Jvw23OYqiKHuhgt5EAqEAP377x0R6Innlgle0V4uiKEccGkNvIo8ueZSMnAzeuPANeiT0CLc5iqIo+6EeehPIKsri7s/vZmr/qVw0+KJwm6MoilIvKuhN4KYPbiIYCvLY1Md00i1FUY5YNORyAGatm8WsdbN4aPJDpCelh9scRVGUBlEPvRFKqkq48f0bGdppKDcff3O4zVEURWkU9dAb4Z7P72F78XbevPBNvG5vuM1RFEVpFPXQG2BZzjL+ueSfXDfmOsanjQ+3OYqiKAdEBb0egqEgP3vvZ3SK7cT9p90fbnMURVGahIZc6uGxpY+xbMcy3rjwDZKiksJtjqIoSpNQD30fdpXu4ref/ZYp/aZon3NFUdoUKuj7cO+8e6kMVPLIlEe0z7miKG0KFfQ6rNm9hmeWP8P1Y65nQIcB4TZHURSlWaigO4RMiBvm3kB8RDx3n3x3uM1RFEVpNtoo6vDs8meZv20+z5zzDKkxqeE2R1EUpdmohw7sLtvNrz7+FZPSJ3H1yKvDbY6iKMpBoYIO3PXZXZT5y3hi2hPaEKooSpulSYIuIlNEZL2IbBSR2+tZf6WI7BGRFc7n/1re1NZhxc4V/Hv5v5kxdgaDUgeF2xxFUZSD5oAxdBFxA48BpwPZwFIRmW2MWbtP0jeMMTNawcZWo7ohNCU6hXtOvifc5iiKohwSTfHQxwEbjTGbjTE+4HVgeuuadXh4KuMpFmQt4G9n/I3k6ORwm6MoinJINEXQuwNZdf5nO8v25QciskpEZopIWn0Zici1IpIhIhl79uw5CHNbju3F27n909uZ3GcyPxn+k7DaoiiK0hI0RdDrayU0+/x/F0g3xgwDPgFeqC8jY8zTxpgxxpgxHTt2bJ6lLYgxhuvnXo8/6OfJaU9qQ6iiKO2Cpgh6NlDX4+4B5NRNYIzJM8ZUOX+fAUa3jHmtw3/X/pfZ62fzh1P+QN+UvuE2R1EUpUVoiqAvBfqLSG8RiQAuAWbXTSAiXev8PRf4ruVMbFnyyvO48f0bGdNtDL84/hfhNkdRFKXFOGAvF2NMQERmAB8CbuA5Y8waEfk9kGGMmQ3cJCLnAgEgH7iyFW0+JH750S/Jr8jno8s+wuPSgbKKorQfmqRoxpi5wNx9lt1T5/cdwB0ta1rLM3/rfF5Y+QJ3nngnw7sMD7c5iqIoLcpRM1I0GApyy4e3kJaQxl0T7wq3OYqiKC3OURNzeGnVS3yz8xteueAVor3R4TZHURSlxTkqPPRSXyl3fnonx3U/jkuHXBpucxRFUVqFo8JDf+jrh9hRuoO3Ln5L+5writJuafeCnlWUxV8X/JVLhlzC+LTxjSc2Bko2QqgK4geAO+LwGKkoitICtPuQyx2f3oHB8OBpDzae0BhYcBm8NwDmDoV3+8HGZ+zy6vVHO8EqCFba38XrIXt24+lbE2MgFKx/nb8EcpdA6db91wV9DW/X0hgD/uKmpa3Kh52f7b+8cjes/bPdp8PNrs9h3SOw5RXIy4BAeePpAxVQtBaKvrPnSjU5H8BXF0NZZuvauy+H6zgfQbRrD33J9iW88u0r3HninfRK6lW7YssrsO5vULwOup4JfX4Ku+fDtldh4M2QPBI2PgVLroXyLHsir38EXF4YdCsM/yMEyiD7f5C7ELpOsR+X2+ZflQfb34OQD5KGQ+q4Axu742OI7gpJQ+x/E4LKPRDdee90wUoo3gDx/cATY5eFAuArgMhU+4RR9K1N1+V0iGpkioWKneCNB08s5HwIOe8BLhhyV+12vgLY8zXkLoaNT9p9GnSbrT9/EQz9vU0fKIHtcyFpKMT3hy3PQ+IQ6HiCvZALv7X1Im7IWwQ7PwGMfRLqeiYUrgZvHBzzK4jq1LDNQR9sex3WPWyP34AZ0Psy8CZByQZ7E85+29YfQIfjIKqzfeqq2AnFayGqC4x5DAqWQ9lW6HgSiAfyFkPOXOhxPvS7BlbdZfc/vj8MuRdy5sD3T0Cscy6FfDDyb3Y/Vt4JeUugao/dx5ieEKyw50/ahdBlsj2HfAUQ3xfG/RtMwApgwgD4+hJ7kxz3NHgTYPPzMO4pyJgB29+FrHdg0lyITKm/XkwIxGVvIlW5ULoJClZA7iJbnx2OszZEJDq2ByF/md3/blNt3fuKbHnlWeCJd86HugjE9rT7Hd0dRv3Nfu/6DLa+CrlfQ8hvk0akQI9zbT7fPw4maM+jkX+xNn73F3vOJI+w52xMGgy9F0o2QeUOiE23NgdKYdsb0OuHtp7q7m95FkR3s9dlNeXbYdU9sONDqNwF6T+C5FFQuMoui+oIwx+w5272bNj5MaSMceom2dqTNKz2WgZ7c8pbbI9vyUZ7fFKPt+dJ5W57TviLoesZ0G2KPd93f2mPgzcOEgbb9P4ie1yCPojrDdFdGj7PDxIxYfI8x4wZYzIyMlotf2MMJ/3nJDYVbGLDjA3ER8bbFdvnwBfn2oOWMhYy/wv+Qrsu/XIY/wKI2BNm8dX2wgJI/7E94XPeg5F/hfX/hPJMKwQmAJEdIHWCPWi5C+1JD4DAyIeg95WQu8DeKBIHQ4fjYc9X0GO6FYBPTrYXZPpl4PJYgS/PhIRBENfP2ugrhJLvrTi5vNDlDOh9OXx7rxUDdwwE63hRkalWIEN+ewPoeJI9ocuz7H6t/bM92cc9BR+OBVeEvRGkjIbTPrMn8NeXQuVOm1+3aVaQchdYu5JHWHGNSLbbBSvsPkR1hYrtdt87nmgv9GqBBXBHQefJ4Im2dVWeDZ44u707Bo69AzpOgKy3bf26PPZCD5RAwUprT+Jge8PI/C97TS3kTbRinHqCFfycOeAvtfsW1RESj4XsWbYewQqPL7/Wrg7jYPcXtXklDbHCB3Yfk4bb+he3tcOE7A3VHQFdz4KYHvZ8KN1sbY/uagUt5LfnW/IIyH7HnifV4gdWJBKPtXVuHM8ysqO9QfS8yDoPJmhvLpEdIHk0DLrZOhsbn7bnlcsDuGw91ZwDHZ2yfNaeHudaAdvwKFQ4M3h4k6DzJCj+ztZz0lBr/6BboP/P7Y24+Dt7Uy7eYI9b9flZTcIg6H6O3T8TtDfGnZ9YUetxHgz+jfXSy515/hKOsdsUroK4vna/q6/D+ohIhuF/sk9d+Rn2mPiLbB79rrWiX7nLfkwI0i6wzsqWl+014U2CLqdB3tJauyNSrNOTtwjKttWWFd3VOm79rrM3vM/PgIodtdsESm19pl1ob5qlm+z5FfLZ+trygnX4sv6X7wAADBBJREFU6hLVBap2114HY5+A/tc1vL+NICLLjDFj6l3XXgX9vQ3vcc5r5/DEtCe4bsx19oCs/5f1khIGweT59u7pL7beoSfGirzUiUKFAlYsE4dC+iX2Tv3hcVC40h708S9akcyZY+/2eYutiKaMht4/sRfe8tsga2ZtntHdnJMuCIi9CCM62PK7TLYnoDfe5tFxgn3srcq1J2REEsT1sU8QhSth03NWjKK7wYAbrYgmDraeTbASlv3CnvwN8f/tnXtwVPUVxz+HAJH3WwkBCQTE5wiINlpAx0cUsCBqW6xOdWprHetUW+2IQ8vYdqaO1rYztrYMKtU6VOPbaHXqo8VHESgi4SEgIfKIxCTyjAQCSU7/ODfDEnbDhrL37i7nM5PZm9/eu/e75/e733t+v3vvb0+62LKrjt2tQV65xrKo968Jsr0my6DP/bPtM7evxaTyZdu2c2/LiHeuMIMbcrVlk9s/sp5O9TtmRAXfsYM6t799Zpd8iz1YA6/bAN0L7LVspm0DZrBg23QfbjHokmcHWl6xnXjrgkx0/3bLevp9zeLXFge+gs0lZvo9R5lJdehocezYFTY+A9Vvw1m/hK759v6yu6xOzvzFweztqwpYMMWy0AkvQLe4k4zCztVmGIMmmeb6rbDq16Z3wHhrNwOLbV8LppihDv02LLgSep0GxYvsO1a+ArtW23et/Y+dOMBiX3C9tSNttFh1L7RtuxfaiWPbEqu3inl2Uj7xQhjxQ4tn+aPWnrTJei4DL247fmCGVfEE5HSxttFntH231jQ3Bica7PjZvdb2P2DCoVnwvlrY/Kx9Ts9TrV5rPwCaLUaLbrKkpUMnO6n2HWcnt08fttj2OsPqp2M3OO1uiwHY8d2413opIgd71t1HQN+xpk3VTiYN26wnWvFXa7ud+9o2HXJh3B9hwEQ4ob99pzUPQdm91iYveh36nA3vXwtVb9hxO+5P1us4UGcJwtbXoMco05hzgulN1F6OwHFn6M3azOg5o9nbuJdPvr+QTivuhc+essY++GqrnKPt7uxeD2sfgjN+nlyFaLNlmnurbJ+Dp5uh15XbAffedMsQLn3PGkJ7OLAbtrwM+VPs5BFv33u/sOxm5woz94ZtpqP/+WYcS2617K7oSRgeTCNcWWqNsNtQGH7TkQ3yWFPzgWVR+VPtAEUPPdGmE81Npi0Vd0/t2RScyHvFf29TiRnygAl2QkyGxj02LBE7fJEJNNbbMdNzFOTkxpTvOdirOJZ18OUiWP0b2+eFpdbDbU3tQhvO6xFM8Ne03xKwgRcfOgx0jDnuDH3+ivnc8NINvDhtDtOr5lhWU/gD60b1SLPZFZsabMghKl3NB2D7x9Dv3NSYkuM4x5S2DD3rLorub9rP7AWzGT3wbK6qnW/dtImvwqDLo5YWn5zcaE8yHTold9HWcZy0J037sUfPY8seo2JHBXPGXYfUvm9X1dPVzB3HcY4hWWXojc2N3P/B/Yw/eTzn7XzbxrcKb45aluM4TihklaGXritlW10ljxYMQarfhlPvOninhOM4TpaTVWPoJUseoqygEyOrnoYh18Apt0UtyXEcJzSyxtDXbX6HB/mQgZ1y4aI3Ie+yqCU5juOEStYMudQs+TEn5UD9hf9wM3cc57gkKwx99441nNfwCQs7j6LPoEuiluM4jhMJWWHo5QtvIwcYcM6DUUtxHMeJjIw3dN33JaN2vstbTf04q3Bq1HIcx3EiI+MNvXLpPXQTZe8pd0QtxXEcJ1Iy29AP1NF383xerc/hsjF3Rq3GcRwnUjLa0PeXP043GljWp/jgfOeO4zjHKRl9H/rOT+dS0wATz/9Z1FIcx3EiJ3Mz9Pqt9N+zhtf2dWHi0IlRq3Ecx4mcjDV03fI8HYDa/heRE/vLJ47jOMcpGTvkUl/+BBsa4MzTvhm1FMdxnLQgMzP0+s/ptutjnq2D4sLiqNU4juOkBZlp6JvtR5fLckeS3zM/YjGO4zjpQUYOuTRvKmFlgzBi6JSopTiO46QNmZeh79lCh20fUlKnXDDkgqjVOI7jpA2ZZ+hbbLjlua+gaHBRxGIcx3HSh8wbchlYzPyOY6g/oZrBPQdHrcZxHCdtyLwMvfcZzP5iF0WDixCRqNU4juOkDRln6DV7aqjYUUFRvg+3OI7jxJJxhr64cjHg4+eO4zityThDL6suI0dyOGfQOVFLcRzHSSuSMnQRuUJE1olIuYjMjPN+roiUBO8vFpGCYy20hVkTZrHlJ1vo2qlrqnbhOI6TkRzR0EUkB3gEmAScDlwnIqe3Wu1mYIeqjgD+ADxwrIXG6CGvR16qPt5xHCdjSSZDPw8oV9UKVd0PPANMa7XONODJYPl54BLxW1Acx3FCJRlDzwe2xPxfGZTFXUdVG4FdQL/WHyQit4jIUhFZWltbe3SKHcdxnLgk82BRvExbj2IdVHUuMBdARGpFZFMS+49Hf+DLo9w21aSrNtfVPlxX+0lXbdmma2iiN5Ix9EpgSMz/g4GtCdapFJGOQC9ge1sfqqoDkth3XERkqaqOO9rtU0m6anNd7cN1tZ901XY86UpmyOW/wEgRGSYinYEZQGmrdUqBG4Pla4F/qephGbrjOI6TOo6Yoatqo4jcDvwTyAHmqepqEfkVsFRVS4HHgadEpBzLzGekUrTjOI5zOElNzqWqrwOvtyqbHbO8Dwjzt+Dmhriv9pKu2lxX+3Bd7SddtR03usRHRhzHcbKDjHv033Ecx4mPG7rjOE6WkHGGfqR5ZULUMURE/i0ia0RktYjcEZTfJyKfi8jy4G9yBNo2isjKYP9Lg7K+IvKWiKwPXvuErGlUTEyWi8huEbkzqniJyDwRqRGRVTFlcWMkxsNBm1shImND1vVbEVkb7PslEekdlBeIyN6Y2M0JWVfCuhORe4N4rRORy1Olqw1tJTG6NorI8qA8lJi14Q+pbWOqmjF/2F02G4DhQGegDDg9Ii15wNhguQfwKTbXzX3A3RHHaSPQv1XZg8DMYHkm8EDE9fgF9oBEJPECJgJjgVVHihEwGXgDe4CuCFgcsq5ioGOw/ECMroLY9SKIV9y6C46DMiAXGBYcszlhamv1/u+A2WHGrA1/SGkby7QMPZl5ZUJBVatUdVmwXAes4fApEdKJ2Pl2ngSuilDLJcAGVT3aJ4X/b1T1PQ5/+C1RjKYBf1NjEdBbRFIyQ1w8Xar6ptqUGgCLsIf7QiVBvBIxDXhGVRtU9TOgHDt2Q9cmIgJ8C3g6VftPoCmRP6S0jWWaoSczr0zoiE0XPAZYHBTdHnSb5oU9tBGgwJsi8pGI3BKUnaSqVWCNDTgxAl0tzODQAyzqeLWQKEbp1O6+h2VyLQwTkY9F5F0RmRCBnnh1l07xmgBUq+r6mLJQY9bKH1LaxjLN0JOaMyZMRKQ78AJwp6ruBv4CFAKjgSqsuxc2X1fVsdiUxz8SkYkRaIiL2NPGU4HngqJ0iNeRSIt2JyKzgEZgflBUBZysqmOAnwJ/F5GeIUpKVHdpEa+A6zg0eQg1ZnH8IeGqccraHbNMM/Rk5pUJDRHphFXWfFV9EUBVq1W1SVWbgUdJYVczEaq6NXitAV4KNFS3dOGC15qwdQVMApapanWgMfJ4xZAoRpG3OxG5EbgSuF6DQddgSGNbsPwRNlZ9Slia2qi7yOMFIDav1NVASUtZmDGL5w+kuI1lmqEnM69MKARjc48Da1T19zHlseNe04FVrbdNsa5uItKjZRm7oLaKQ+fbuRF4JUxdMRySMUUdr1YkilEp8N3gToQiYFdLtzkMROQK4B5gqqrWx5QPEPsBGkRkODASqAhRV6K6KwVmiP2S2bBA15KwdMVwKbBWVStbCsKKWSJ/INVtLNVXe1Nw9XgydsV4AzArQh3jsS7RCmB58DcZeApYGZSXAnkh6xqO3WFQBqxuiRE2P/07wPrgtW8EMesKbAN6xZRFEi/spFIFHMCyo5sTxQjrDj8StLmVwLiQdZVj46st7WxOsO41QR2XAcuAb4SsK2HdAbOCeK0DJoVdl0H5E8CtrdYNJWZt+ENK25g/+u84jpMlZNqQi+M4jpMAN3THcZwswQ3dcRwnS3BDdxzHyRLc0B3HcbIEN3THcZwswQ3dcRwnS/gf2o1vor6rSQgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_acc_and_cel(baseline_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discuss the Baseline model:**  \n",
    "For the Baseline model, I looked at using a VGG-based architecture. This is a general architecture in image classification. It uses stacked, 3x3 convolutional filters that feed in to a maxpooling layer (forming a block). these blocks are repeated to increase the depth of the network. Each layer also uses the Relu activatation func. the hidden layer output is flattened and fed to softmax in the output layer consisting of 100 nodes each for a possible class. In terms of optimizers, I use stochastic gradient descent (sgd). This will optimize the cross entropy function.\n",
    "\n",
    "**Observation:**    \n",
    "At first I tried one block for the hidden layers of my VGG network, but this showed an even larger amount of overfitting than seen in the Cross Entropy Loss plot above (note the green represents training data performance, and the yellow is validation performance). Increasing the blocks from 1 to 3 reduced the rate of covergance between the training and validation data, though the overfitting is cleary visible at around 12 epochs. The accuracy of this model landed on 99% accuracy on the training, and 36% on the validation. The overfitting mentioned may indicate that a model which uses means of regularization may be best. Using a dropout regularization model may This would slow down the convergance of the validation and training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define a regularization model that uses dropout regularization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_regularization_model(): \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(100, activation='softmax'))   \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile and fit a regularization model using sgd optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = make_regularization_model()\n",
    "\n",
    "# compile with SGD optimizer model\n",
    "sgd_opt = SGD(lr=0.001, momentum=0.9)\n",
    "cnn_model.compile(optimizer=sgd_opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47500 samples, validate on 2500 samples\n",
      "Epoch 1/200\n",
      "47500/47500 [==============================] - 11s 236us/step - loss: 4.5891 - accuracy: 0.0151 - val_loss: 4.4995 - val_accuracy: 0.0312\n",
      "Epoch 2/200\n",
      "47500/47500 [==============================] - 11s 228us/step - loss: 4.3883 - accuracy: 0.0372 - val_loss: 4.2085 - val_accuracy: 0.0752\n",
      "Epoch 3/200\n",
      "47500/47500 [==============================] - 11s 229us/step - loss: 4.1751 - accuracy: 0.0640 - val_loss: 4.0250 - val_accuracy: 0.1036\n",
      "Epoch 4/200\n",
      "47500/47500 [==============================] - 11s 230us/step - loss: 3.9924 - accuracy: 0.0899 - val_loss: 3.8392 - val_accuracy: 0.1212\n",
      "Epoch 5/200\n",
      "47500/47500 [==============================] - 11s 229us/step - loss: 3.8164 - accuracy: 0.1132 - val_loss: 3.6754 - val_accuracy: 0.1520\n",
      "Epoch 6/200\n",
      "47500/47500 [==============================] - 11s 231us/step - loss: 3.6624 - accuracy: 0.1381 - val_loss: 3.5197 - val_accuracy: 0.1768\n",
      "Epoch 7/200\n",
      "47500/47500 [==============================] - 11s 233us/step - loss: 3.5373 - accuracy: 0.1617 - val_loss: 3.4165 - val_accuracy: 0.1920\n",
      "Epoch 8/200\n",
      "47500/47500 [==============================] - 11s 230us/step - loss: 3.4323 - accuracy: 0.1800 - val_loss: 3.3467 - val_accuracy: 0.2024\n",
      "Epoch 9/200\n",
      "47500/47500 [==============================] - 11s 230us/step - loss: 3.3368 - accuracy: 0.1949 - val_loss: 3.1987 - val_accuracy: 0.2260\n",
      "Epoch 10/200\n",
      "47500/47500 [==============================] - 11s 229us/step - loss: 3.2450 - accuracy: 0.2138 - val_loss: 3.0911 - val_accuracy: 0.2532\n",
      "Epoch 11/200\n",
      "47500/47500 [==============================] - 11s 230us/step - loss: 3.1751 - accuracy: 0.2245 - val_loss: 2.9955 - val_accuracy: 0.2688\n",
      "Epoch 12/200\n",
      "47500/47500 [==============================] - 11s 229us/step - loss: 3.0839 - accuracy: 0.2412 - val_loss: 2.9050 - val_accuracy: 0.2828\n",
      "Epoch 13/200\n",
      "47500/47500 [==============================] - 11s 231us/step - loss: 3.0037 - accuracy: 0.2554 - val_loss: 2.9572 - val_accuracy: 0.2716\n",
      "Epoch 14/200\n",
      "47500/47500 [==============================] - 11s 229us/step - loss: 2.9303 - accuracy: 0.2678 - val_loss: 2.7765 - val_accuracy: 0.3076\n",
      "Epoch 15/200\n",
      "47500/47500 [==============================] - 11s 229us/step - loss: 2.8602 - accuracy: 0.2811 - val_loss: 2.7701 - val_accuracy: 0.3184\n",
      "Epoch 16/200\n",
      "47500/47500 [==============================] - 12s 257us/step - loss: 2.7958 - accuracy: 0.2965 - val_loss: 2.6949 - val_accuracy: 0.3264\n",
      "Epoch 17/200\n",
      "47500/47500 [==============================] - 11s 236us/step - loss: 2.7297 - accuracy: 0.3070 - val_loss: 2.6338 - val_accuracy: 0.3328\n",
      "Epoch 18/200\n",
      "47500/47500 [==============================] - 11s 238us/step - loss: 2.6688 - accuracy: 0.3188 - val_loss: 2.5938 - val_accuracy: 0.3452\n",
      "Epoch 19/200\n",
      "47500/47500 [==============================] - 11s 240us/step - loss: 2.6149 - accuracy: 0.3279 - val_loss: 2.4603 - val_accuracy: 0.3796\n",
      "Epoch 20/200\n",
      "47500/47500 [==============================] - 11s 239us/step - loss: 2.5622 - accuracy: 0.3400 - val_loss: 2.4632 - val_accuracy: 0.3840\n",
      "Epoch 21/200\n",
      "47500/47500 [==============================] - 11s 236us/step - loss: 2.5165 - accuracy: 0.3502 - val_loss: 2.5069 - val_accuracy: 0.3688\n",
      "Epoch 22/200\n",
      "47500/47500 [==============================] - 11s 234us/step - loss: 2.4756 - accuracy: 0.3588 - val_loss: 2.3821 - val_accuracy: 0.3900\n",
      "Epoch 23/200\n",
      "47500/47500 [==============================] - 11s 239us/step - loss: 2.4230 - accuracy: 0.3700 - val_loss: 2.4206 - val_accuracy: 0.3860\n",
      "Epoch 24/200\n",
      "47500/47500 [==============================] - 11s 237us/step - loss: 2.3840 - accuracy: 0.3780 - val_loss: 2.3639 - val_accuracy: 0.3960\n",
      "Epoch 25/200\n",
      "47500/47500 [==============================] - 11s 237us/step - loss: 2.3493 - accuracy: 0.3846 - val_loss: 2.2651 - val_accuracy: 0.4192\n",
      "Epoch 26/200\n",
      "47500/47500 [==============================] - 12s 261us/step - loss: 2.3105 - accuracy: 0.3921 - val_loss: 2.3003 - val_accuracy: 0.4068\n",
      "Epoch 27/200\n",
      "47500/47500 [==============================] - 12s 252us/step - loss: 2.2735 - accuracy: 0.3996 - val_loss: 2.2055 - val_accuracy: 0.4308\n",
      "Epoch 28/200\n",
      "47500/47500 [==============================] - 12s 246us/step - loss: 2.2408 - accuracy: 0.4079 - val_loss: 2.2347 - val_accuracy: 0.4240\n",
      "Epoch 29/200\n",
      "47500/47500 [==============================] - 12s 252us/step - loss: 2.2032 - accuracy: 0.4174 - val_loss: 2.1944 - val_accuracy: 0.4300\n",
      "Epoch 30/200\n",
      "47500/47500 [==============================] - 11s 228us/step - loss: 2.1749 - accuracy: 0.4225 - val_loss: 2.1459 - val_accuracy: 0.4520\n",
      "Epoch 31/200\n",
      "47500/47500 [==============================] - 14s 291us/step - loss: 2.1302 - accuracy: 0.4315 - val_loss: 2.2049 - val_accuracy: 0.4380\n",
      "Epoch 32/200\n",
      "47500/47500 [==============================] - 11s 230us/step - loss: 2.1107 - accuracy: 0.4357 - val_loss: 2.1523 - val_accuracy: 0.4372\n",
      "Epoch 33/200\n",
      "47500/47500 [==============================] - 14s 296us/step - loss: 2.0811 - accuracy: 0.4418 - val_loss: 2.1069 - val_accuracy: 0.4508\n",
      "Epoch 34/200\n",
      "47500/47500 [==============================] - 11s 230us/step - loss: 2.0547 - accuracy: 0.4485 - val_loss: 2.0551 - val_accuracy: 0.4636\n",
      "Epoch 35/200\n",
      "47500/47500 [==============================] - 15s 311us/step - loss: 2.0269 - accuracy: 0.4533 - val_loss: 2.0844 - val_accuracy: 0.4564\n",
      "Epoch 36/200\n",
      "47500/47500 [==============================] - 12s 258us/step - loss: 1.9985 - accuracy: 0.4609 - val_loss: 2.0937 - val_accuracy: 0.4548\n",
      "Epoch 37/200\n",
      "47500/47500 [==============================] - 14s 295us/step - loss: 1.9701 - accuracy: 0.4627 - val_loss: 2.0875 - val_accuracy: 0.4496\n",
      "Epoch 38/200\n",
      "47500/47500 [==============================] - 12s 249us/step - loss: 1.9439 - accuracy: 0.4732 - val_loss: 2.0975 - val_accuracy: 0.4568\n",
      "Epoch 39/200\n",
      "47500/47500 [==============================] - 11s 239us/step - loss: 1.9139 - accuracy: 0.4797 - val_loss: 2.0633 - val_accuracy: 0.4596\n",
      "Epoch 40/200\n",
      "47500/47500 [==============================] - 12s 259us/step - loss: 1.8951 - accuracy: 0.4833 - val_loss: 2.0078 - val_accuracy: 0.4816\n",
      "Epoch 41/200\n",
      "47500/47500 [==============================] - 12s 254us/step - loss: 1.8726 - accuracy: 0.4864 - val_loss: 2.0749 - val_accuracy: 0.4676\n",
      "Epoch 42/200\n",
      "47500/47500 [==============================] - 12s 261us/step - loss: 1.8453 - accuracy: 0.4937 - val_loss: 2.0201 - val_accuracy: 0.4736\n",
      "Epoch 43/200\n",
      "47500/47500 [==============================] - 14s 299us/step - loss: 1.8208 - accuracy: 0.5002 - val_loss: 2.0340 - val_accuracy: 0.4600\n",
      "Epoch 44/200\n",
      "47500/47500 [==============================] - 12s 247us/step - loss: 1.8152 - accuracy: 0.5015 - val_loss: 1.9901 - val_accuracy: 0.4712\n",
      "Epoch 45/200\n",
      "47500/47500 [==============================] - 13s 268us/step - loss: 1.7875 - accuracy: 0.5081 - val_loss: 2.0113 - val_accuracy: 0.4808\n",
      "Epoch 46/200\n",
      "47500/47500 [==============================] - 14s 289us/step - loss: 1.7585 - accuracy: 0.5110 - val_loss: 1.9903 - val_accuracy: 0.4768loss: 1.7587 - ac\n",
      "Epoch 47/200\n",
      "47500/47500 [==============================] - 11s 230us/step - loss: 1.7477 - accuracy: 0.5144 - val_loss: 1.9505 - val_accuracy: 0.4920\n",
      "Epoch 48/200\n",
      "47500/47500 [==============================] - 14s 288us/step - loss: 1.7143 - accuracy: 0.5239 - val_loss: 2.0512 - val_accuracy: 0.4704\n",
      "Epoch 49/200\n",
      "47500/47500 [==============================] - 11s 226us/step - loss: 1.6925 - accuracy: 0.5293 - val_loss: 1.9700 - val_accuracy: 0.4856\n",
      "Epoch 50/200\n",
      "47500/47500 [==============================] - 11s 237us/step - loss: 1.6774 - accuracy: 0.5319 - val_loss: 1.9507 - val_accuracy: 0.4868\n",
      "Epoch 51/200\n",
      "47500/47500 [==============================] - 11s 230us/step - loss: 1.6629 - accuracy: 0.5329 - val_loss: 2.0021 - val_accuracy: 0.4832\n",
      "Epoch 52/200\n",
      "47500/47500 [==============================] - 13s 269us/step - loss: 1.6493 - accuracy: 0.5352 - val_loss: 1.9825 - val_accuracy: 0.4796\n",
      "Epoch 53/200\n",
      "47500/47500 [==============================] - 16s 338us/step - loss: 1.6237 - accuracy: 0.5417 - val_loss: 1.9634 - val_accuracy: 0.4892\n",
      "Epoch 54/200\n",
      "47500/47500 [==============================] - 14s 304us/step - loss: 1.6136 - accuracy: 0.5445 - val_loss: 1.9593 - val_accuracy: 0.4896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200\n",
      "47500/47500 [==============================] - 14s 290us/step - loss: 1.5862 - accuracy: 0.5525 - val_loss: 1.9468 - val_accuracy: 0.4872\n",
      "Epoch 56/200\n",
      "47500/47500 [==============================] - 13s 273us/step - loss: 1.5709 - accuracy: 0.5552 - val_loss: 1.9366 - val_accuracy: 0.4920\n",
      "Epoch 57/200\n",
      "47500/47500 [==============================] - 14s 298us/step - loss: 1.5537 - accuracy: 0.5624 - val_loss: 1.9181 - val_accuracy: 0.5064\n",
      "Epoch 58/200\n",
      "47500/47500 [==============================] - 14s 293us/step - loss: 1.5336 - accuracy: 0.5647 - val_loss: 1.9554 - val_accuracy: 0.4932\n",
      "Epoch 59/200\n",
      "47500/47500 [==============================] - 14s 290us/step - loss: 1.5255 - accuracy: 0.5655 - val_loss: 1.9361 - val_accuracy: 0.4924\n",
      "Epoch 60/200\n",
      "47500/47500 [==============================] - 13s 273us/step - loss: 1.5054 - accuracy: 0.5717 - val_loss: 1.9442 - val_accuracy: 0.4896\n",
      "Epoch 61/200\n",
      "47500/47500 [==============================] - 14s 292us/step - loss: 1.4895 - accuracy: 0.5735 - val_loss: 1.9580 - val_accuracy: 0.4940\n",
      "Epoch 62/200\n",
      "47500/47500 [==============================] - 15s 311us/step - loss: 1.4743 - accuracy: 0.5781 - val_loss: 1.9381 - val_accuracy: 0.49441.4728 - \n",
      "Epoch 63/200\n",
      "47500/47500 [==============================] - 13s 276us/step - loss: 1.4544 - accuracy: 0.5820 - val_loss: 1.9247 - val_accuracy: 0.4944\n",
      "Epoch 64/200\n",
      "47500/47500 [==============================] - 14s 292us/step - loss: 1.4440 - accuracy: 0.5843 - val_loss: 2.0005 - val_accuracy: 0.4916\n",
      "Epoch 65/200\n",
      "47500/47500 [==============================] - 13s 276us/step - loss: 1.4285 - accuracy: 0.5867 - val_loss: 1.9427 - val_accuracy: 0.4980\n",
      "Epoch 66/200\n",
      "47500/47500 [==============================] - 15s 317us/step - loss: 1.4125 - accuracy: 0.5913 - val_loss: 1.9599 - val_accuracy: 0.4888\n",
      "Epoch 67/200\n",
      "47500/47500 [==============================] - 13s 275us/step - loss: 1.3984 - accuracy: 0.5965 - val_loss: 1.9472 - val_accuracy: 0.4928\n",
      "Epoch 68/200\n",
      "47500/47500 [==============================] - 14s 298us/step - loss: 1.3911 - accuracy: 0.5985 - val_loss: 1.9398 - val_accuracy: 0.5096\n",
      "Epoch 69/200\n",
      "47500/47500 [==============================] - 14s 292us/step - loss: 1.3734 - accuracy: 0.6002 - val_loss: 1.9601 - val_accuracy: 0.4968\n",
      "Epoch 70/200\n",
      "47500/47500 [==============================] - 14s 297us/step - loss: 1.3630 - accuracy: 0.6044 - val_loss: 1.9680 - val_accuracy: 0.4912\n",
      "Epoch 71/200\n",
      "47500/47500 [==============================] - 14s 294us/step - loss: 1.3401 - accuracy: 0.6076 - val_loss: 1.9922 - val_accuracy: 0.4964\n",
      "Epoch 72/200\n",
      "47500/47500 [==============================] - 12s 258us/step - loss: 1.3331 - accuracy: 0.6080 - val_loss: 1.9373 - val_accuracy: 0.5068\n",
      "Epoch 73/200\n",
      "47500/47500 [==============================] - 15s 312us/step - loss: 1.3213 - accuracy: 0.6136 - val_loss: 2.0005 - val_accuracy: 0.4956\n",
      "Epoch 74/200\n",
      "47500/47500 [==============================] - 14s 294us/step - loss: 1.3049 - accuracy: 0.6198 - val_loss: 1.9925 - val_accuracy: 0.4996\n",
      "Epoch 75/200\n",
      "47500/47500 [==============================] - 11s 229us/step - loss: 1.3007 - accuracy: 0.6201 - val_loss: 1.9328 - val_accuracy: 0.5100\n",
      "Epoch 76/200\n",
      "47500/47500 [==============================] - 15s 306us/step - loss: 1.2869 - accuracy: 0.6244 - val_loss: 2.0580 - val_accuracy: 0.4960\n",
      "Epoch 77/200\n",
      "47500/47500 [==============================] - 15s 325us/step - loss: 1.2719 - accuracy: 0.6256 - val_loss: 1.9591 - val_accuracy: 0.5056\n",
      "Epoch 78/200\n",
      "47500/47500 [==============================] - 13s 269us/step - loss: 1.2546 - accuracy: 0.6289 - val_loss: 1.9592 - val_accuracy: 0.5084\n",
      "Epoch 79/200\n",
      "47500/47500 [==============================] - 13s 273us/step - loss: 1.2436 - accuracy: 0.6309 - val_loss: 1.9712 - val_accuracy: 0.5040\n",
      "Epoch 80/200\n",
      "47500/47500 [==============================] - 12s 254us/step - loss: 1.2400 - accuracy: 0.6315 - val_loss: 2.0057 - val_accuracy: 0.5080\n",
      "Epoch 81/200\n",
      "47500/47500 [==============================] - 11s 234us/step - loss: 1.2277 - accuracy: 0.6347 - val_loss: 1.9761 - val_accuracy: 0.5008\n",
      "Epoch 82/200\n",
      "47500/47500 [==============================] - 12s 250us/step - loss: 1.2153 - accuracy: 0.6391 - val_loss: 1.9855 - val_accuracy: 0.5104\n",
      "Epoch 83/200\n",
      "47500/47500 [==============================] - 12s 262us/step - loss: 1.1993 - accuracy: 0.6435 - val_loss: 1.9914 - val_accuracy: 0.4980\n",
      "Epoch 84/200\n",
      "47500/47500 [==============================] - 16s 335us/step - loss: 1.1950 - accuracy: 0.6431 - val_loss: 1.9476 - val_accuracy: 0.5116\n",
      "Epoch 85/200\n",
      "47500/47500 [==============================] - 11s 226us/step - loss: 1.1833 - accuracy: 0.6475 - val_loss: 1.9790 - val_accuracy: 0.5048\n",
      "Epoch 86/200\n",
      "47500/47500 [==============================] - 14s 289us/step - loss: 1.1744 - accuracy: 0.6493 - val_loss: 2.0682 - val_accuracy: 0.4916\n",
      "Epoch 87/200\n",
      "47500/47500 [==============================] - 11s 228us/step - loss: 1.1665 - accuracy: 0.6529 - val_loss: 1.9926 - val_accuracy: 0.5076\n",
      "Epoch 88/200\n",
      "47500/47500 [==============================] - 14s 293us/step - loss: 1.1500 - accuracy: 0.6533 - val_loss: 1.9996 - val_accuracy: 0.5076\n",
      "Epoch 89/200\n",
      "47500/47500 [==============================] - 11s 228us/step - loss: 1.1540 - accuracy: 0.6538 - val_loss: 2.0463 - val_accuracy: 0.4940\n",
      "Epoch 90/200\n",
      "47500/47500 [==============================] - 14s 289us/step - loss: 1.1354 - accuracy: 0.6589 - val_loss: 2.0522 - val_accuracy: 0.4984\n",
      "Epoch 91/200\n",
      "47500/47500 [==============================] - 11s 226us/step - loss: 1.1279 - accuracy: 0.6623 - val_loss: 2.0163 - val_accuracy: 0.5104\n",
      "Epoch 92/200\n",
      "47500/47500 [==============================] - 14s 288us/step - loss: 1.1202 - accuracy: 0.6644 - val_loss: 1.9967 - val_accuracy: 0.5164\n",
      "Epoch 93/200\n",
      "47500/47500 [==============================] - 11s 226us/step - loss: 1.1114 - accuracy: 0.6645 - val_loss: 2.0305 - val_accuracy: 0.5016\n",
      "Epoch 94/200\n",
      "47500/47500 [==============================] - 14s 292us/step - loss: 1.1016 - accuracy: 0.6675 - val_loss: 2.0240 - val_accuracy: 0.5112\n",
      "Epoch 95/200\n",
      "47500/47500 [==============================] - 11s 226us/step - loss: 1.0928 - accuracy: 0.6725 - val_loss: 2.0224 - val_accuracy: 0.5096\n",
      "Epoch 96/200\n",
      "47500/47500 [==============================] - 15s 307us/step - loss: 1.0963 - accuracy: 0.6692 - val_loss: 2.0054 - val_accuracy: 0.5000\n",
      "Epoch 97/200\n",
      "47500/47500 [==============================] - 11s 227us/step - loss: 1.0743 - accuracy: 0.6781 - val_loss: 2.0160 - val_accuracy: 0.5100\n",
      "Epoch 98/200\n",
      "47500/47500 [==============================] - 15s 306us/step - loss: 1.0710 - accuracy: 0.6761 - val_loss: 2.0256 - val_accuracy: 0.5104\n",
      "Epoch 99/200\n",
      "47500/47500 [==============================] - 11s 228us/step - loss: 1.0499 - accuracy: 0.6822 - val_loss: 2.0777 - val_accuracy: 0.5136\n",
      "Epoch 100/200\n",
      "47500/47500 [==============================] - 15s 308us/step - loss: 1.0529 - accuracy: 0.6820 - val_loss: 2.0949 - val_accuracy: 0.5100\n",
      "Epoch 101/200\n",
      "47500/47500 [==============================] - 13s 271us/step - loss: 1.0435 - accuracy: 0.6829 - val_loss: 2.0822 - val_accuracy: 0.5084\n",
      "Epoch 102/200\n",
      "47500/47500 [==============================] - 12s 254us/step - loss: 1.0361 - accuracy: 0.6842 - val_loss: 2.0436 - val_accuracy: 0.5064\n",
      "Epoch 103/200\n",
      "47500/47500 [==============================] - 13s 280us/step - loss: 1.0348 - accuracy: 0.6834 - val_loss: 2.1166 - val_accuracy: 0.5016\n",
      "Epoch 104/200\n",
      "47500/47500 [==============================] - 12s 248us/step - loss: 1.0145 - accuracy: 0.6920 - val_loss: 2.1032 - val_accuracy: 0.5012\n",
      "Epoch 105/200\n",
      "47500/47500 [==============================] - 15s 312us/step - loss: 1.0128 - accuracy: 0.6908 - val_loss: 2.0263 - val_accuracy: 0.5100\n",
      "Epoch 106/200\n",
      "47500/47500 [==============================] - 11s 229us/step - loss: 1.0083 - accuracy: 0.6939 - val_loss: 2.1080 - val_accuracy: 0.5048\n",
      "Epoch 107/200\n",
      "47500/47500 [==============================] - 13s 282us/step - loss: 0.9970 - accuracy: 0.6926 - val_loss: 2.0623 - val_accuracy: 0.5052\n",
      "Epoch 108/200\n",
      "47500/47500 [==============================] - 12s 262us/step - loss: 0.9898 - accuracy: 0.6989 - val_loss: 2.0593 - val_accuracy: 0.5068\n",
      "Epoch 109/200\n",
      "47500/47500 [==============================] - 13s 269us/step - loss: 0.9832 - accuracy: 0.6995 - val_loss: 2.0726 - val_accuracy: 0.5148\n",
      "Epoch 110/200\n",
      "47500/47500 [==============================] - 11s 228us/step - loss: 0.9839 - accuracy: 0.7008 - val_loss: 2.0974 - val_accuracy: 0.5080\n",
      "Epoch 111/200\n",
      "47500/47500 [==============================] - 13s 268us/step - loss: 0.9726 - accuracy: 0.7029 - val_loss: 2.0723 - val_accuracy: 0.5032\n",
      "Epoch 112/200\n",
      "47500/47500 [==============================] - 15s 308us/step - loss: 0.9660 - accuracy: 0.7017 - val_loss: 2.1133 - val_accuracy: 0.5060\n",
      "Epoch 113/200\n",
      "47500/47500 [==============================] - 14s 291us/step - loss: 0.9690 - accuracy: 0.7043 - val_loss: 2.0912 - val_accuracy: 0.5104\n",
      "Epoch 114/200\n",
      "47500/47500 [==============================] - 12s 246us/step - loss: 0.9578 - accuracy: 0.7032 - val_loss: 2.1303 - val_accuracy: 0.4992\n",
      "Epoch 115/200\n",
      "47500/47500 [==============================] - 13s 265us/step - loss: 0.9568 - accuracy: 0.7064 - val_loss: 2.0698 - val_accuracy: 0.5080\n",
      "Epoch 116/200\n",
      "47500/47500 [==============================] - 12s 248us/step - loss: 0.9405 - accuracy: 0.7113 - val_loss: 2.0953 - val_accuracy: 0.5096\n",
      "Epoch 117/200\n",
      "47500/47500 [==============================] - 12s 249us/step - loss: 0.9258 - accuracy: 0.7159 - val_loss: 2.0720 - val_accuracy: 0.5096\n",
      "Epoch 118/200\n",
      "47500/47500 [==============================] - 13s 266us/step - loss: 0.9299 - accuracy: 0.7152 - val_loss: 2.1367 - val_accuracy: 0.5044\n",
      "Epoch 119/200\n",
      "47500/47500 [==============================] - 15s 318us/step - loss: 0.9325 - accuracy: 0.7124 - val_loss: 2.1276 - val_accuracy: 0.5076\n",
      "Epoch 120/200\n",
      "47500/47500 [==============================] - 15s 325us/step - loss: 0.9162 - accuracy: 0.7176 - val_loss: 2.0959 - val_accuracy: 0.5020\n",
      "Epoch 121/200\n",
      "47500/47500 [==============================] - 14s 295us/step - loss: 0.9191 - accuracy: 0.7148 - val_loss: 2.1237 - val_accuracy: 0.5108\n",
      "Epoch 122/200\n",
      "47500/47500 [==============================] - 12s 247us/step - loss: 0.9072 - accuracy: 0.7171 - val_loss: 2.0161 - val_accuracy: 0.5164\n",
      "Epoch 123/200\n",
      "47500/47500 [==============================] - 12s 253us/step - loss: 0.9003 - accuracy: 0.7201 - val_loss: 2.1094 - val_accuracy: 0.5088\n",
      "Epoch 124/200\n",
      "47500/47500 [==============================] - 12s 247us/step - loss: 0.9038 - accuracy: 0.7203 - val_loss: 2.0988 - val_accuracy: 0.5144\n",
      "Epoch 125/200\n",
      "47500/47500 [==============================] - 14s 288us/step - loss: 0.8928 - accuracy: 0.7239 - val_loss: 2.0743 - val_accuracy: 0.5092\n",
      "Epoch 126/200\n",
      "47500/47500 [==============================] - 13s 270us/step - loss: 0.8862 - accuracy: 0.7267 - val_loss: 2.1067 - val_accuracy: 0.5092l\n",
      "Epoch 127/200\n",
      "47500/47500 [==============================] - 13s 269us/step - loss: 0.8762 - accuracy: 0.7276 - val_loss: 2.1281 - val_accuracy: 0.5124\n",
      "Epoch 128/200\n",
      "47500/47500 [==============================] - 12s 251us/step - loss: 0.8765 - accuracy: 0.7291 - val_loss: 2.0981 - val_accuracy: 0.5092\n",
      "Epoch 129/200\n",
      "47500/47500 [==============================] - 12s 249us/step - loss: 0.8661 - accuracy: 0.7315 - val_loss: 2.1565 - val_accuracy: 0.4968\n",
      "Epoch 130/200\n",
      "47500/47500 [==============================] - 12s 249us/step - loss: 0.8601 - accuracy: 0.7311 - val_loss: 2.1310 - val_accuracy: 0.5060\n",
      "Epoch 131/200\n",
      "47500/47500 [==============================] - 13s 268us/step - loss: 0.8655 - accuracy: 0.7321 - val_loss: 2.1694 - val_accuracy: 0.5016\n",
      "Epoch 132/200\n",
      "47500/47500 [==============================] - 12s 248us/step - loss: 0.8550 - accuracy: 0.7320 - val_loss: 2.1384 - val_accuracy: 0.5120\n",
      "Epoch 133/200\n",
      "47500/47500 [==============================] - 13s 284us/step - loss: 0.8612 - accuracy: 0.7305 - val_loss: 2.1267 - val_accuracy: 0.5176\n",
      "Epoch 134/200\n",
      "47500/47500 [==============================] - 13s 266us/step - loss: 0.8566 - accuracy: 0.7331 - val_loss: 2.1443 - val_accuracy: 0.5120\n",
      "Epoch 135/200\n",
      "47500/47500 [==============================] - 15s 310us/step - loss: 0.8401 - accuracy: 0.7370 - val_loss: 2.1316 - val_accuracy: 0.5112\n",
      "Epoch 136/200\n",
      "47500/47500 [==============================] - 11s 226us/step - loss: 0.8386 - accuracy: 0.7386 - val_loss: 2.1162 - val_accuracy: 0.5152\n",
      "Epoch 137/200\n",
      "47500/47500 [==============================] - 14s 289us/step - loss: 0.8349 - accuracy: 0.7408 - val_loss: 2.1440 - val_accuracy: 0.5084\n",
      "Epoch 138/200\n",
      "47500/47500 [==============================] - 12s 244us/step - loss: 0.8242 - accuracy: 0.7431 - val_loss: 2.1397 - val_accuracy: 0.5060\n",
      "Epoch 139/200\n",
      "47500/47500 [==============================] - 14s 305us/step - loss: 0.8280 - accuracy: 0.7410 - val_loss: 2.2176 - val_accuracy: 0.5060\n",
      "Epoch 140/200\n",
      "47500/47500 [==============================] - 11s 226us/step - loss: 0.8212 - accuracy: 0.7439 - val_loss: 2.1614 - val_accuracy: 0.5116\n",
      "Epoch 141/200\n",
      "47500/47500 [==============================] - 14s 289us/step - loss: 0.8171 - accuracy: 0.7433 - val_loss: 2.1734 - val_accuracy: 0.5152\n",
      "Epoch 142/200\n",
      "47500/47500 [==============================] - 11s 227us/step - loss: 0.8116 - accuracy: 0.7473 - val_loss: 2.1736 - val_accuracy: 0.5188\n",
      "Epoch 143/200\n",
      "47500/47500 [==============================] - 13s 272us/step - loss: 0.8116 - accuracy: 0.7459 - val_loss: 2.1536 - val_accuracy: 0.5216\n",
      "Epoch 144/200\n",
      "47500/47500 [==============================] - 11s 228us/step - loss: 0.7976 - accuracy: 0.7495 - val_loss: 2.2047 - val_accuracy: 0.5140\n",
      "Epoch 145/200\n",
      "47500/47500 [==============================] - 13s 272us/step - loss: 0.8027 - accuracy: 0.7494 - val_loss: 2.1481 - val_accuracy: 0.5144\n",
      "Epoch 146/200\n",
      "47500/47500 [==============================] - 12s 248us/step - loss: 0.7879 - accuracy: 0.7544 - val_loss: 2.2106 - val_accuracy: 0.5144\n",
      "Epoch 147/200\n",
      "47500/47500 [==============================] - 14s 305us/step - loss: 0.8038 - accuracy: 0.7493 - val_loss: 2.1260 - val_accuracy: 0.5164\n",
      "Epoch 148/200\n",
      "47500/47500 [==============================] - 11s 232us/step - loss: 0.7951 - accuracy: 0.7507 - val_loss: 2.1556 - val_accuracy: 0.5168\n",
      "Epoch 149/200\n",
      "47500/47500 [==============================] - 14s 296us/step - loss: 0.7830 - accuracy: 0.7539 - val_loss: 2.2188 - val_accuracy: 0.5156\n",
      "Epoch 150/200\n",
      "47500/47500 [==============================] - 12s 251us/step - loss: 0.7762 - accuracy: 0.7544 - val_loss: 2.1511 - val_accuracy: 0.5300\n",
      "Epoch 151/200\n",
      "47500/47500 [==============================] - 14s 294us/step - loss: 0.7846 - accuracy: 0.7524 - val_loss: 2.1678 - val_accuracy: 0.5100\n",
      "Epoch 152/200\n",
      "47500/47500 [==============================] - 11s 228us/step - loss: 0.7812 - accuracy: 0.7553 - val_loss: 2.1555 - val_accuracy: 0.5168\n",
      "Epoch 153/200\n",
      "47500/47500 [==============================] - 14s 292us/step - loss: 0.7774 - accuracy: 0.7578 - val_loss: 2.1381 - val_accuracy: 0.5168\n",
      "Epoch 154/200\n",
      "47500/47500 [==============================] - 11s 228us/step - loss: 0.7721 - accuracy: 0.7599 - val_loss: 2.2142 - val_accuracy: 0.5180\n",
      "Epoch 155/200\n",
      "47500/47500 [==============================] - 15s 308us/step - loss: 0.7560 - accuracy: 0.7609 - val_loss: 2.2909 - val_accuracy: 0.5000\n",
      "Epoch 156/200\n",
      "47500/47500 [==============================] - 11s 230us/step - loss: 0.7579 - accuracy: 0.7639 - val_loss: 2.2168 - val_accuracy: 0.5136\n",
      "Epoch 157/200\n",
      "47500/47500 [==============================] - 15s 310us/step - loss: 0.7608 - accuracy: 0.7611 - val_loss: 2.2418 - val_accuracy: 0.5064\n",
      "Epoch 158/200\n",
      "47500/47500 [==============================] - 11s 229us/step - loss: 0.7588 - accuracy: 0.7617 - val_loss: 2.2245 - val_accuracy: 0.5184\n",
      "Epoch 159/200\n",
      "47500/47500 [==============================] - 14s 293us/step - loss: 0.7455 - accuracy: 0.7649 - val_loss: 2.2222 - val_accuracy: 0.5108\n",
      "Epoch 160/200\n",
      "47500/47500 [==============================] - 12s 248us/step - loss: 0.7527 - accuracy: 0.7647 - val_loss: 2.1888 - val_accuracy: 0.5136\n",
      "Epoch 161/200\n",
      "47500/47500 [==============================] - 16s 333us/step - loss: 0.7502 - accuracy: 0.7637 - val_loss: 2.1879 - val_accuracy: 0.5208\n",
      "Epoch 162/200\n",
      "47500/47500 [==============================] - 16s 334us/step - loss: 0.7466 - accuracy: 0.7649 - val_loss: 2.1577 - val_accuracy: 0.5140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 163/200\n",
      "47500/47500 [==============================] - 15s 309us/step - loss: 0.7345 - accuracy: 0.7683 - val_loss: 2.1738 - val_accuracy: 0.5164\n",
      "Epoch 164/200\n",
      "47500/47500 [==============================] - 14s 294us/step - loss: 0.7423 - accuracy: 0.7654 - val_loss: 2.2607 - val_accuracy: 0.5076\n",
      "Epoch 165/200\n",
      "47500/47500 [==============================] - 15s 311us/step - loss: 0.7309 - accuracy: 0.7716 - val_loss: 2.2566 - val_accuracy: 0.5124\n",
      "Epoch 166/200\n",
      "47500/47500 [==============================] - 15s 317us/step - loss: 0.7284 - accuracy: 0.7691 - val_loss: 2.2394 - val_accuracy: 0.5096\n",
      "Epoch 167/200\n",
      "47500/47500 [==============================] - 16s 330us/step - loss: 0.7252 - accuracy: 0.7699 - val_loss: 2.2231 - val_accuracy: 0.5196\n",
      "Epoch 168/200\n",
      "47500/47500 [==============================] - 13s 275us/step - loss: 0.7260 - accuracy: 0.7711 - val_loss: 2.2132 - val_accuracy: 0.5156\n",
      "Epoch 169/200\n",
      "47500/47500 [==============================] - 14s 295us/step - loss: 0.7144 - accuracy: 0.7748 - val_loss: 2.3063 - val_accuracy: 0.5084\n",
      "Epoch 170/200\n",
      "47500/47500 [==============================] - 12s 254us/step - loss: 0.7259 - accuracy: 0.7690 - val_loss: 2.2160 - val_accuracy: 0.5240\n",
      "Epoch 171/200\n",
      "47500/47500 [==============================] - 15s 314us/step - loss: 0.7183 - accuracy: 0.7728 - val_loss: 2.2473 - val_accuracy: 0.5104\n",
      "Epoch 172/200\n",
      "47500/47500 [==============================] - 14s 295us/step - loss: 0.7204 - accuracy: 0.7744 - val_loss: 2.1932 - val_accuracy: 0.5148\n",
      "Epoch 173/200\n",
      "47500/47500 [==============================] - 12s 254us/step - loss: 0.7073 - accuracy: 0.7768 - val_loss: 2.2370 - val_accuracy: 0.5088\n",
      "Epoch 174/200\n",
      "47500/47500 [==============================] - 16s 333us/step - loss: 0.7069 - accuracy: 0.7774 - val_loss: 2.2830 - val_accuracy: 0.5164\n",
      "Epoch 175/200\n",
      "47500/47500 [==============================] - 12s 248us/step - loss: 0.7117 - accuracy: 0.7734 - val_loss: 2.2543 - val_accuracy: 0.5172\n",
      "Epoch 176/200\n",
      "47500/47500 [==============================] - 14s 293us/step - loss: 0.7007 - accuracy: 0.7788 - val_loss: 2.2160 - val_accuracy: 0.5176\n",
      "Epoch 177/200\n",
      "47500/47500 [==============================] - 14s 290us/step - loss: 0.7051 - accuracy: 0.7773 - val_loss: 2.2545 - val_accuracy: 0.5160\n",
      "Epoch 178/200\n",
      "47500/47500 [==============================] - 11s 231us/step - loss: 0.6891 - accuracy: 0.7805 - val_loss: 2.2347 - val_accuracy: 0.5216\n",
      "Epoch 179/200\n",
      "47500/47500 [==============================] - 15s 326us/step - loss: 0.6934 - accuracy: 0.7808 - val_loss: 2.2573 - val_accuracy: 0.5140\n",
      "Epoch 180/200\n",
      "47500/47500 [==============================] - 16s 337us/step - loss: 0.6981 - accuracy: 0.7785 - val_loss: 2.3494 - val_accuracy: 0.5048\n",
      "Epoch 181/200\n",
      "47500/47500 [==============================] - 14s 291us/step - loss: 0.6900 - accuracy: 0.7822 - val_loss: 2.3016 - val_accuracy: 0.5156\n",
      "Epoch 182/200\n",
      "47500/47500 [==============================] - 12s 249us/step - loss: 0.6852 - accuracy: 0.7828 - val_loss: 2.2809 - val_accuracy: 0.5200\n",
      "Epoch 183/200\n",
      "47500/47500 [==============================] - 14s 289us/step - loss: 0.6777 - accuracy: 0.7862 - val_loss: 2.2224 - val_accuracy: 0.5184\n",
      "Epoch 184/200\n",
      "47500/47500 [==============================] - 12s 251us/step - loss: 0.6773 - accuracy: 0.7856 - val_loss: 2.2583 - val_accuracy: 0.5156\n",
      "Epoch 185/200\n",
      "47500/47500 [==============================] - 16s 339us/step - loss: 0.6845 - accuracy: 0.7835 - val_loss: 2.2286 - val_accuracy: 0.5148\n",
      "Epoch 186/200\n",
      "47500/47500 [==============================] - 12s 244us/step - loss: 0.6657 - accuracy: 0.7886 - val_loss: 2.2993 - val_accuracy: 0.5092\n",
      "Epoch 187/200\n",
      "47500/47500 [==============================] - 14s 292us/step - loss: 0.6747 - accuracy: 0.7861 - val_loss: 2.2867 - val_accuracy: 0.5028\n",
      "Epoch 188/200\n",
      "47500/47500 [==============================] - 11s 232us/step - loss: 0.6709 - accuracy: 0.7873 - val_loss: 2.3293 - val_accuracy: 0.5064\n",
      "Epoch 189/200\n",
      "47500/47500 [==============================] - 14s 294us/step - loss: 0.6746 - accuracy: 0.7854 - val_loss: 2.2876 - val_accuracy: 0.5200\n",
      "Epoch 190/200\n",
      "47500/47500 [==============================] - 11s 231us/step - loss: 0.6721 - accuracy: 0.7882 - val_loss: 2.2825 - val_accuracy: 0.5200\n",
      "Epoch 191/200\n",
      "47500/47500 [==============================] - 15s 311us/step - loss: 0.6658 - accuracy: 0.7886 - val_loss: 2.2855 - val_accuracy: 0.5136\n",
      "Epoch 192/200\n",
      "47500/47500 [==============================] - 14s 295us/step - loss: 0.6629 - accuracy: 0.7891 - val_loss: 2.1842 - val_accuracy: 0.5292\n",
      "Epoch 193/200\n",
      "47500/47500 [==============================] - 12s 254us/step - loss: 0.6617 - accuracy: 0.7898 - val_loss: 2.2902 - val_accuracy: 0.5224\n",
      "Epoch 194/200\n",
      "47500/47500 [==============================] - 13s 274us/step - loss: 0.6589 - accuracy: 0.7898 - val_loss: 2.2551 - val_accuracy: 0.5232\n",
      "Epoch 195/200\n",
      "47500/47500 [==============================] - 14s 303us/step - loss: 0.6649 - accuracy: 0.7899 - val_loss: 2.2593 - val_accuracy: 0.5172\n",
      "Epoch 196/200\n",
      "47500/47500 [==============================] - 15s 320us/step - loss: 0.6585 - accuracy: 0.7910 - val_loss: 2.2443 - val_accuracy: 0.5212\n",
      "Epoch 197/200\n",
      "47500/47500 [==============================] - 15s 317us/step - loss: 0.6542 - accuracy: 0.7919 - val_loss: 2.3032 - val_accuracy: 0.5192\n",
      "Epoch 198/200\n",
      "47500/47500 [==============================] - 11s 232us/step - loss: 0.6460 - accuracy: 0.7933 - val_loss: 2.3231 - val_accuracy: 0.5188\n",
      "Epoch 199/200\n",
      "47500/47500 [==============================] - 15s 315us/step - loss: 0.6553 - accuracy: 0.7917 - val_loss: 2.2476 - val_accuracy: 0.5196\n",
      "Epoch 200/200\n",
      "47500/47500 [==============================] - 14s 292us/step - loss: 0.6448 - accuracy: 0.7942 - val_loss: 2.2344 - val_accuracy: 0.5208\n"
     ]
    }
   ],
   "source": [
    "cnn_history = cnn_model.fit(X_train, y_train,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=(X_dev, y_dev),\n",
    "                            workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_acc_and_cel(cnn_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discuss the CNN:**  \n",
    "Dropout regularization is a technique that drops a fixed number of node each epoch. I use this in for the cnn model by adding a dropout after every maxpooling layer. I set the rate of droupout to .2, which means 20% nodes will be dropped. I use the same optimizer as in the VGG model, and the ouput layer is also softmax. \n",
    "\n",
    "**Observations:** \n",
    "As I hoped, the Cross Entropy Loss plot shown above indicates that the rate of convergence between the green(training) and the yellow(validation) decreased, and does not converge until approx the 30th epoch. It's clear that 200 epochs may be too high a starting point, as the models' performances thus far have stopped improving well before even the 100th epoch. The resultin accuracy on the test after the 200th epoch landed at 79%, and 52% on the validation. It would be possible to try a wight decay model using L2 wight regularization, but given the time contraints, I will keras's data augmentation capability to see how it performs on this image set (mainly cause I've been wanting to give it a try, not because I expect it to be the best model for this task.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile and fit a data augmentation model using RMSprop optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_augmentation_model(): \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=X_train.shape[1:]))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation_model = make_data_augmentation_model()\n",
    "\n",
    "# compile model with RMSprop optimizer\n",
    "data_augmentation_model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6),\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "# This will do preprocessing and realtime data augmentation:\n",
    "# horizontal flip randomly flip images\n",
    "datagen = ImageDataGenerator(\n",
    "                            fill_mode='nearest',\n",
    "                            cval=0.,\n",
    "                            horizontal_flip=True,  \n",
    "                            data_format=\"channels_last\")\n",
    "\n",
    "# Compute quantities required for feature-wise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "950/950 [==============================] - 13s 14ms/step - loss: 4.3754 - accuracy: 0.0366 - val_loss: 4.0925 - val_accuracy: 0.0940\n",
      "Epoch 2/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 4.0142 - accuracy: 0.0863 - val_loss: 3.7543 - val_accuracy: 0.1508\n",
      "Epoch 3/200\n",
      "950/950 [==============================] - 11s 12ms/step - loss: 3.7508 - accuracy: 0.1304 - val_loss: 3.5255 - val_accuracy: 0.1904\n",
      "Epoch 4/200\n",
      "950/950 [==============================] - 12s 13ms/step - loss: 3.5695 - accuracy: 0.1609 - val_loss: 3.3876 - val_accuracy: 0.2144\n",
      "Epoch 5/200\n",
      "950/950 [==============================] - 11s 12ms/step - loss: 3.4335 - accuracy: 0.1847 - val_loss: 3.2437 - val_accuracy: 0.2312\n",
      "Epoch 6/200\n",
      "950/950 [==============================] - 13s 14ms/step - loss: 3.3221 - accuracy: 0.2044 - val_loss: 3.1645 - val_accuracy: 0.2424\n",
      "Epoch 7/200\n",
      "950/950 [==============================] - 15s 16ms/step - loss: 3.2185 - accuracy: 0.2219 - val_loss: 3.0581 - val_accuracy: 0.2636\n",
      "Epoch 8/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 3.1400 - accuracy: 0.2372 - val_loss: 3.0015 - val_accuracy: 0.2808\n",
      "Epoch 9/200\n",
      "950/950 [==============================] - 13s 14ms/step - loss: 3.0640 - accuracy: 0.2513 - val_loss: 2.9246 - val_accuracy: 0.2912\n",
      "Epoch 10/200\n",
      "950/950 [==============================] - 11s 12ms/step - loss: 3.0029 - accuracy: 0.2623 - val_loss: 2.8586 - val_accuracy: 0.3052\n",
      "Epoch 11/200\n",
      "950/950 [==============================] - 12s 13ms/step - loss: 2.9409 - accuracy: 0.2723 - val_loss: 2.8050 - val_accuracy: 0.3160\n",
      "Epoch 12/200\n",
      "950/950 [==============================] - 15s 16ms/step - loss: 2.8916 - accuracy: 0.2842 - val_loss: 2.7902 - val_accuracy: 0.3164\n",
      "Epoch 13/200\n",
      "950/950 [==============================] - 12s 12ms/step - loss: 2.8393 - accuracy: 0.2944 - val_loss: 2.7093 - val_accuracy: 0.3324\n",
      "Epoch 14/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.8018 - accuracy: 0.2995 - val_loss: 2.7283 - val_accuracy: 0.3324\n",
      "Epoch 15/200\n",
      "950/950 [==============================] - 11s 12ms/step - loss: 2.7556 - accuracy: 0.3103 - val_loss: 2.6641 - val_accuracy: 0.3460\n",
      "Epoch 16/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.7175 - accuracy: 0.3192 - val_loss: 2.6212 - val_accuracy: 0.3652\n",
      "Epoch 17/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.6780 - accuracy: 0.3264 - val_loss: 2.5964 - val_accuracy: 0.3520\n",
      "Epoch 18/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.6489 - accuracy: 0.3329 - val_loss: 2.5604 - val_accuracy: 0.3660\n",
      "Epoch 19/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.6182 - accuracy: 0.3419 - val_loss: 2.5495 - val_accuracy: 0.3704\n",
      "Epoch 20/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.5837 - accuracy: 0.3476 - val_loss: 2.5128 - val_accuracy: 0.3748\n",
      "Epoch 21/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.5602 - accuracy: 0.3522 - val_loss: 2.4909 - val_accuracy: 0.3840\n",
      "Epoch 22/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.5393 - accuracy: 0.3582 - val_loss: 2.4645 - val_accuracy: 0.3792\n",
      "Epoch 23/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.5036 - accuracy: 0.3644 - val_loss: 2.4924 - val_accuracy: 0.3756\n",
      "Epoch 24/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.4825 - accuracy: 0.3681 - val_loss: 2.4210 - val_accuracy: 0.3996\n",
      "Epoch 25/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.4611 - accuracy: 0.3733 - val_loss: 2.3924 - val_accuracy: 0.4008\n",
      "Epoch 26/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.4315 - accuracy: 0.3804 - val_loss: 2.3830 - val_accuracy: 0.4048\n",
      "Epoch 27/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.4185 - accuracy: 0.3822 - val_loss: 2.3413 - val_accuracy: 0.4164\n",
      "Epoch 28/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.4077 - accuracy: 0.3827 - val_loss: 2.3269 - val_accuracy: 0.4112\n",
      "Epoch 29/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.3788 - accuracy: 0.3914 - val_loss: 2.3095 - val_accuracy: 0.4248\n",
      "Epoch 30/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.3688 - accuracy: 0.3932 - val_loss: 2.3106 - val_accuracy: 0.4176\n",
      "Epoch 31/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.3478 - accuracy: 0.3993 - val_loss: 2.3073 - val_accuracy: 0.4184\n",
      "Epoch 32/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.3326 - accuracy: 0.4028 - val_loss: 2.2690 - val_accuracy: 0.4296\n",
      "Epoch 33/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.3285 - accuracy: 0.4036 - val_loss: 2.2645 - val_accuracy: 0.4276\n",
      "Epoch 34/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.3127 - accuracy: 0.4064 - val_loss: 2.2818 - val_accuracy: 0.4280\n",
      "Epoch 35/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.2996 - accuracy: 0.4093 - val_loss: 2.2482 - val_accuracy: 0.4320\n",
      "Epoch 36/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.2779 - accuracy: 0.4132 - val_loss: 2.2347 - val_accuracy: 0.4380\n",
      "Epoch 37/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.2720 - accuracy: 0.4158 - val_loss: 2.2080 - val_accuracy: 0.4360\n",
      "Epoch 38/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.2522 - accuracy: 0.4204 - val_loss: 2.1878 - val_accuracy: 0.4448\n",
      "Epoch 39/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.2507 - accuracy: 0.4228 - val_loss: 2.1937 - val_accuracy: 0.4480\n",
      "Epoch 40/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.2403 - accuracy: 0.4242 - val_loss: 2.2102 - val_accuracy: 0.4408\n",
      "Epoch 41/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.2245 - accuracy: 0.4265 - val_loss: 2.2056 - val_accuracy: 0.4372\n",
      "Epoch 42/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.2226 - accuracy: 0.4259 - val_loss: 2.1848 - val_accuracy: 0.4400\n",
      "Epoch 43/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.2069 - accuracy: 0.4291 - val_loss: 2.1426 - val_accuracy: 0.4540\n",
      "Epoch 44/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.2107 - accuracy: 0.4316 - val_loss: 2.1468 - val_accuracy: 0.4592\n",
      "Epoch 45/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.1988 - accuracy: 0.4323 - val_loss: 2.1530 - val_accuracy: 0.4456\n",
      "Epoch 46/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.1934 - accuracy: 0.4343 - val_loss: 2.1624 - val_accuracy: 0.4472\n",
      "Epoch 47/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.1852 - accuracy: 0.4375 - val_loss: 2.1222 - val_accuracy: 0.4560\n",
      "Epoch 48/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.1680 - accuracy: 0.4393 - val_loss: 2.1261 - val_accuracy: 0.4556\n",
      "Epoch 49/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.1668 - accuracy: 0.4400 - val_loss: 2.1147 - val_accuracy: 0.4652\n",
      "Epoch 50/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.1603 - accuracy: 0.4412 - val_loss: 2.1266 - val_accuracy: 0.4564\n",
      "Epoch 51/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.1539 - accuracy: 0.4430 - val_loss: 2.1036 - val_accuracy: 0.4588\n",
      "Epoch 52/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.1551 - accuracy: 0.4458 - val_loss: 2.0775 - val_accuracy: 0.4732\n",
      "Epoch 53/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.1526 - accuracy: 0.4462 - val_loss: 2.1307 - val_accuracy: 0.4612\n",
      "Epoch 54/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.1301 - accuracy: 0.4506 - val_loss: 2.0826 - val_accuracy: 0.4664\n",
      "Epoch 55/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.1333 - accuracy: 0.4478 - val_loss: 2.1003 - val_accuracy: 0.4640\n",
      "Epoch 56/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.1314 - accuracy: 0.4477 - val_loss: 2.0798 - val_accuracy: 0.4696\n",
      "Epoch 57/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.1264 - accuracy: 0.4508 - val_loss: 2.0757 - val_accuracy: 0.4692\n",
      "Epoch 58/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.1266 - accuracy: 0.4497 - val_loss: 2.0770 - val_accuracy: 0.4708\n",
      "Epoch 59/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.1082 - accuracy: 0.4537 - val_loss: 2.1381 - val_accuracy: 0.4696\n",
      "Epoch 60/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.1167 - accuracy: 0.4538 - val_loss: 2.0720 - val_accuracy: 0.4700\n",
      "Epoch 61/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.1155 - accuracy: 0.4538 - val_loss: 2.0950 - val_accuracy: 0.4736\n",
      "Epoch 62/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.1088 - accuracy: 0.4566 - val_loss: 2.0654 - val_accuracy: 0.4716\n",
      "Epoch 63/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.1032 - accuracy: 0.4560 - val_loss: 2.0654 - val_accuracy: 0.4740\n",
      "Epoch 64/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.0956 - accuracy: 0.4588 - val_loss: 2.0280 - val_accuracy: 0.4816\n",
      "Epoch 65/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.1024 - accuracy: 0.4609 - val_loss: 2.0416 - val_accuracy: 0.4780\n",
      "Epoch 66/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0860 - accuracy: 0.4623 - val_loss: 2.0450 - val_accuracy: 0.4832\n",
      "Epoch 67/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0933 - accuracy: 0.4615 - val_loss: 2.0668 - val_accuracy: 0.4812\n",
      "Epoch 68/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0905 - accuracy: 0.4601 - val_loss: 2.0728 - val_accuracy: 0.4784\n",
      "Epoch 69/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0753 - accuracy: 0.4647 - val_loss: 2.0494 - val_accuracy: 0.4788\n",
      "Epoch 70/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0823 - accuracy: 0.4597 - val_loss: 2.0499 - val_accuracy: 0.4772\n",
      "Epoch 71/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0801 - accuracy: 0.4643 - val_loss: 2.0316 - val_accuracy: 0.4828\n",
      "Epoch 72/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0782 - accuracy: 0.4633 - val_loss: 2.0778 - val_accuracy: 0.4744\n",
      "Epoch 73/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0767 - accuracy: 0.4632 - val_loss: 2.0294 - val_accuracy: 0.4840\n",
      "Epoch 74/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0733 - accuracy: 0.4637 - val_loss: 2.0432 - val_accuracy: 0.4832\n",
      "Epoch 75/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0745 - accuracy: 0.4636 - val_loss: 2.0543 - val_accuracy: 0.4796\n",
      "Epoch 76/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0677 - accuracy: 0.4660 - val_loss: 2.0540 - val_accuracy: 0.4712\n",
      "Epoch 77/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0654 - accuracy: 0.4687 - val_loss: 2.0236 - val_accuracy: 0.4800\n",
      "Epoch 78/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0625 - accuracy: 0.4670 - val_loss: 2.0022 - val_accuracy: 0.4836\n",
      "Epoch 79/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0662 - accuracy: 0.4625 - val_loss: 2.0260 - val_accuracy: 0.4860\n",
      "Epoch 80/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0666 - accuracy: 0.4650 - val_loss: 2.0219 - val_accuracy: 0.4808\n",
      "Epoch 81/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0510 - accuracy: 0.4690 - val_loss: 2.0425 - val_accuracy: 0.4928\n",
      "Epoch 82/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0555 - accuracy: 0.4697 - val_loss: 2.0331 - val_accuracy: 0.4840\n",
      "Epoch 83/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0589 - accuracy: 0.4679 - val_loss: 2.0113 - val_accuracy: 0.4900\n",
      "Epoch 84/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0595 - accuracy: 0.4690 - val_loss: 2.0198 - val_accuracy: 0.4908\n",
      "Epoch 85/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0527 - accuracy: 0.4669 - val_loss: 2.0189 - val_accuracy: 0.4824\n",
      "Epoch 86/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0587 - accuracy: 0.4674 - val_loss: 2.0343 - val_accuracy: 0.4804\n",
      "Epoch 87/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0539 - accuracy: 0.4703 - val_loss: 2.0495 - val_accuracy: 0.4804\n",
      "Epoch 88/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0522 - accuracy: 0.4713 - val_loss: 2.0511 - val_accuracy: 0.4768\n",
      "Epoch 89/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0520 - accuracy: 0.4679 - val_loss: 1.9990 - val_accuracy: 0.4836\n",
      "Epoch 90/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0472 - accuracy: 0.4704 - val_loss: 2.0429 - val_accuracy: 0.4840\n",
      "Epoch 91/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0475 - accuracy: 0.4684 - val_loss: 2.0680 - val_accuracy: 0.4792\n",
      "Epoch 92/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0398 - accuracy: 0.4720 - val_loss: 2.0252 - val_accuracy: 0.4800\n",
      "Epoch 93/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0394 - accuracy: 0.4716 - val_loss: 2.0588 - val_accuracy: 0.4864\n",
      "Epoch 94/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0495 - accuracy: 0.4690 - val_loss: 2.0278 - val_accuracy: 0.4888\n",
      "Epoch 95/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0463 - accuracy: 0.4709 - val_loss: 2.0030 - val_accuracy: 0.4816\n",
      "Epoch 96/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0367 - accuracy: 0.4715 - val_loss: 1.9896 - val_accuracy: 0.4888\n",
      "Epoch 97/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0362 - accuracy: 0.4742 - val_loss: 1.9985 - val_accuracy: 0.4900\n",
      "Epoch 98/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0443 - accuracy: 0.4718 - val_loss: 2.0936 - val_accuracy: 0.4832\n",
      "Epoch 99/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0513 - accuracy: 0.4702 - val_loss: 1.9803 - val_accuracy: 0.4956\n",
      "Epoch 100/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0376 - accuracy: 0.4723 - val_loss: 2.0242 - val_accuracy: 0.4832\n",
      "Epoch 101/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0422 - accuracy: 0.4709 - val_loss: 1.9781 - val_accuracy: 0.4924\n",
      "Epoch 102/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0388 - accuracy: 0.4728 - val_loss: 2.0402 - val_accuracy: 0.4864\n",
      "Epoch 103/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0312 - accuracy: 0.4751 - val_loss: 2.0046 - val_accuracy: 0.4884\n",
      "Epoch 104/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0263 - accuracy: 0.4761 - val_loss: 2.0256 - val_accuracy: 0.4848\n",
      "Epoch 105/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0365 - accuracy: 0.4710 - val_loss: 1.9776 - val_accuracy: 0.4920\n",
      "Epoch 106/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0374 - accuracy: 0.4706 - val_loss: 2.0137 - val_accuracy: 0.4880\n",
      "Epoch 107/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0404 - accuracy: 0.4732 - val_loss: 1.9790 - val_accuracy: 0.5036\n",
      "Epoch 108/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0366 - accuracy: 0.4722 - val_loss: 1.9582 - val_accuracy: 0.4956\n",
      "Epoch 109/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0374 - accuracy: 0.4710 - val_loss: 2.0265 - val_accuracy: 0.4880\n",
      "Epoch 110/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0383 - accuracy: 0.4747 - val_loss: 2.0543 - val_accuracy: 0.4924\n",
      "Epoch 111/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0304 - accuracy: 0.4721 - val_loss: 2.0062 - val_accuracy: 0.4872\n",
      "Epoch 112/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0388 - accuracy: 0.4711 - val_loss: 2.0109 - val_accuracy: 0.4912\n",
      "Epoch 113/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0323 - accuracy: 0.4727 - val_loss: 2.0128 - val_accuracy: 0.4884\n",
      "Epoch 114/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0365 - accuracy: 0.4724 - val_loss: 2.0178 - val_accuracy: 0.4832\n",
      "Epoch 115/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0335 - accuracy: 0.4741 - val_loss: 2.0269 - val_accuracy: 0.4844\n",
      "Epoch 116/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0299 - accuracy: 0.4731 - val_loss: 1.9933 - val_accuracy: 0.4944\n",
      "Epoch 117/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0288 - accuracy: 0.4757 - val_loss: 1.9797 - val_accuracy: 0.4988\n",
      "Epoch 118/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0317 - accuracy: 0.4722 - val_loss: 2.0050 - val_accuracy: 0.4988\n",
      "Epoch 119/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0293 - accuracy: 0.4740 - val_loss: 2.0167 - val_accuracy: 0.4896\n",
      "Epoch 120/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0301 - accuracy: 0.4730 - val_loss: 2.0153 - val_accuracy: 0.4908\n",
      "Epoch 121/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0379 - accuracy: 0.4718 - val_loss: 1.9460 - val_accuracy: 0.5004\n",
      "Epoch 122/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0304 - accuracy: 0.4742 - val_loss: 1.9943 - val_accuracy: 0.5064\n",
      "Epoch 123/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0268 - accuracy: 0.4766 - val_loss: 2.0074 - val_accuracy: 0.4872\n",
      "Epoch 124/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0240 - accuracy: 0.4779 - val_loss: 1.9963 - val_accuracy: 0.4956\n",
      "Epoch 125/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0296 - accuracy: 0.4726 - val_loss: 1.9595 - val_accuracy: 0.4996\n",
      "Epoch 126/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0260 - accuracy: 0.4712 - val_loss: 2.0935 - val_accuracy: 0.4864\n",
      "Epoch 127/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0242 - accuracy: 0.4703 - val_loss: 2.0287 - val_accuracy: 0.4984\n",
      "Epoch 128/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0260 - accuracy: 0.4746 - val_loss: 2.0151 - val_accuracy: 0.5036\n",
      "Epoch 129/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0323 - accuracy: 0.4745 - val_loss: 1.9732 - val_accuracy: 0.5020\n",
      "Epoch 130/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0312 - accuracy: 0.4772 - val_loss: 2.1315 - val_accuracy: 0.4856\n",
      "Epoch 131/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0267 - accuracy: 0.4729 - val_loss: 2.0866 - val_accuracy: 0.4948\n",
      "Epoch 132/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.0297 - accuracy: 0.4716 - val_loss: 2.0246 - val_accuracy: 0.4916\n",
      "Epoch 133/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0261 - accuracy: 0.4741 - val_loss: 2.0069 - val_accuracy: 0.4956\n",
      "Epoch 134/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0259 - accuracy: 0.4748 - val_loss: 2.0108 - val_accuracy: 0.4900\n",
      "Epoch 135/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0347 - accuracy: 0.4721 - val_loss: 2.0668 - val_accuracy: 0.4968\n",
      "Epoch 136/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0194 - accuracy: 0.4736 - val_loss: 1.9904 - val_accuracy: 0.4836\n",
      "Epoch 137/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0290 - accuracy: 0.4735 - val_loss: 2.0058 - val_accuracy: 0.4968\n",
      "Epoch 138/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0207 - accuracy: 0.4779 - val_loss: 1.9948 - val_accuracy: 0.5016\n",
      "Epoch 139/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.0315 - accuracy: 0.4732 - val_loss: 1.9425 - val_accuracy: 0.5044\n",
      "Epoch 140/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0304 - accuracy: 0.4746 - val_loss: 2.0519 - val_accuracy: 0.4808\n",
      "Epoch 141/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0243 - accuracy: 0.4733 - val_loss: 2.0218 - val_accuracy: 0.4944\n",
      "Epoch 142/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0219 - accuracy: 0.4751 - val_loss: 2.0221 - val_accuracy: 0.4948\n",
      "Epoch 143/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0232 - accuracy: 0.4759 - val_loss: 1.9882 - val_accuracy: 0.5020\n",
      "Epoch 144/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.0251 - accuracy: 0.4732 - val_loss: 2.0396 - val_accuracy: 0.4880\n",
      "Epoch 145/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0296 - accuracy: 0.4769 - val_loss: 1.9750 - val_accuracy: 0.4984\n",
      "Epoch 146/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0205 - accuracy: 0.4762 - val_loss: 2.0146 - val_accuracy: 0.4912\n",
      "Epoch 147/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0226 - accuracy: 0.4760 - val_loss: 1.9870 - val_accuracy: 0.4996\n",
      "Epoch 148/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.0191 - accuracy: 0.4763 - val_loss: 2.0040 - val_accuracy: 0.4888\n",
      "Epoch 149/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0161 - accuracy: 0.4752 - val_loss: 2.0178 - val_accuracy: 0.4992\n",
      "Epoch 150/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0179 - accuracy: 0.4760 - val_loss: 1.9513 - val_accuracy: 0.4984\n",
      "Epoch 151/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0189 - accuracy: 0.4762 - val_loss: 1.9980 - val_accuracy: 0.4920\n",
      "Epoch 152/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.0159 - accuracy: 0.4762 - val_loss: 1.9858 - val_accuracy: 0.4904\n",
      "Epoch 153/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0160 - accuracy: 0.4755 - val_loss: 1.9911 - val_accuracy: 0.5020\n",
      "Epoch 154/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0115 - accuracy: 0.4776 - val_loss: 1.9973 - val_accuracy: 0.4996\n",
      "Epoch 155/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0178 - accuracy: 0.4747 - val_loss: 1.9824 - val_accuracy: 0.4960\n",
      "Epoch 156/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0276 - accuracy: 0.4720 - val_loss: 1.9475 - val_accuracy: 0.5032\n",
      "Epoch 157/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0203 - accuracy: 0.4751 - val_loss: 2.2291 - val_accuracy: 0.4808\n",
      "Epoch 158/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.0154 - accuracy: 0.4765 - val_loss: 2.0113 - val_accuracy: 0.4908\n",
      "Epoch 159/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0171 - accuracy: 0.4751 - val_loss: 1.9777 - val_accuracy: 0.5068\n",
      "Epoch 160/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0176 - accuracy: 0.4739 - val_loss: 1.9780 - val_accuracy: 0.4972\n",
      "Epoch 161/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0125 - accuracy: 0.4776 - val_loss: 1.9701 - val_accuracy: 0.5028\n",
      "Epoch 162/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0062 - accuracy: 0.4768 - val_loss: 2.0401 - val_accuracy: 0.5028\n",
      "Epoch 163/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0139 - accuracy: 0.4748 - val_loss: 2.0355 - val_accuracy: 0.4880\n",
      "Epoch 164/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0213 - accuracy: 0.4741 - val_loss: 1.9540 - val_accuracy: 0.5108\n",
      "Epoch 165/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.0203 - accuracy: 0.4748 - val_loss: 1.9726 - val_accuracy: 0.5028\n",
      "Epoch 166/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0166 - accuracy: 0.4758 - val_loss: 1.9521 - val_accuracy: 0.5044\n",
      "Epoch 167/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0114 - accuracy: 0.4767 - val_loss: 2.0521 - val_accuracy: 0.4968\n",
      "Epoch 168/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 2.0105 - accuracy: 0.4761 - val_loss: 2.0239 - val_accuracy: 0.4956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0048 - accuracy: 0.4810 - val_loss: 1.9941 - val_accuracy: 0.5020\n",
      "Epoch 170/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0153 - accuracy: 0.4773 - val_loss: 1.9526 - val_accuracy: 0.4968\n",
      "Epoch 171/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0101 - accuracy: 0.4783 - val_loss: 2.0602 - val_accuracy: 0.4944\n",
      "Epoch 172/200\n",
      "950/950 [==============================] - 10s 11ms/step - loss: 1.9999 - accuracy: 0.4808 - val_loss: 1.9781 - val_accuracy: 0.5040\n",
      "Epoch 173/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0137 - accuracy: 0.4763 - val_loss: 2.0153 - val_accuracy: 0.4836\n",
      "Epoch 174/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0133 - accuracy: 0.4784 - val_loss: 1.9508 - val_accuracy: 0.5008\n",
      "Epoch 175/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0139 - accuracy: 0.4774 - val_loss: 2.0144 - val_accuracy: 0.4900\n",
      "Epoch 176/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0123 - accuracy: 0.4770 - val_loss: 1.9660 - val_accuracy: 0.4988\n",
      "Epoch 177/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0169 - accuracy: 0.4772 - val_loss: 1.9540 - val_accuracy: 0.5016\n",
      "Epoch 178/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0012 - accuracy: 0.4783 - val_loss: 1.9795 - val_accuracy: 0.4912\n",
      "Epoch 179/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0056 - accuracy: 0.4764 - val_loss: 2.0002 - val_accuracy: 0.4960\n",
      "Epoch 180/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0053 - accuracy: 0.4800 - val_loss: 2.1430 - val_accuracy: 0.4912\n",
      "Epoch 181/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0006 - accuracy: 0.4807 - val_loss: 1.9751 - val_accuracy: 0.5040\n",
      "Epoch 182/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0086 - accuracy: 0.4761 - val_loss: 1.9981 - val_accuracy: 0.4940\n",
      "Epoch 183/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0014 - accuracy: 0.4796 - val_loss: 2.0112 - val_accuracy: 0.5008\n",
      "Epoch 184/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0033 - accuracy: 0.4761 - val_loss: 1.9512 - val_accuracy: 0.4956\n",
      "Epoch 185/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0000 - accuracy: 0.4789 - val_loss: 1.9769 - val_accuracy: 0.4920\n",
      "Epoch 186/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 1.9947 - accuracy: 0.4807 - val_loss: 2.0091 - val_accuracy: 0.5036\n",
      "Epoch 187/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 1.9990 - accuracy: 0.4780 - val_loss: 2.0108 - val_accuracy: 0.4968\n",
      "Epoch 188/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 1.9904 - accuracy: 0.4806 - val_loss: 1.9887 - val_accuracy: 0.4988\n",
      "Epoch 189/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0002 - accuracy: 0.4784 - val_loss: 1.9959 - val_accuracy: 0.4944\n",
      "Epoch 190/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 1.9960 - accuracy: 0.4813 - val_loss: 2.0322 - val_accuracy: 0.4996\n",
      "Epoch 191/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 2.0009 - accuracy: 0.4799 - val_loss: 2.0023 - val_accuracy: 0.4992\n",
      "Epoch 192/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 1.9923 - accuracy: 0.4796 - val_loss: 1.9737 - val_accuracy: 0.5068\n",
      "Epoch 193/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 1.9958 - accuracy: 0.4811 - val_loss: 1.9561 - val_accuracy: 0.5012\n",
      "Epoch 194/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 1.9962 - accuracy: 0.4800 - val_loss: 2.0559 - val_accuracy: 0.4880\n",
      "Epoch 195/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 1.9994 - accuracy: 0.4802 - val_loss: 1.9895 - val_accuracy: 0.5036\n",
      "Epoch 196/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 1.9917 - accuracy: 0.4812 - val_loss: 2.0052 - val_accuracy: 0.4940\n",
      "Epoch 197/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 1.9948 - accuracy: 0.4792 - val_loss: 1.9834 - val_accuracy: 0.5092\n",
      "Epoch 198/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 1.9977 - accuracy: 0.4824 - val_loss: 2.0000 - val_accuracy: 0.5008\n",
      "Epoch 199/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 1.9908 - accuracy: 0.4831 - val_loss: 1.9778 - val_accuracy: 0.5052\n",
      "Epoch 200/200\n",
      "950/950 [==============================] - 10s 10ms/step - loss: 1.9939 - accuracy: 0.4836 - val_loss: 1.9226 - val_accuracy: 0.5088\n"
     ]
    }
   ],
   "source": [
    "# Fit the model on the batches generated by datagen.flow().\n",
    "data_aug_history = data_augmentation_model.fit_generator(datagen.flow(X_train, y_train,\n",
    "                                batch_size=batch_size),\n",
    "                                epochs=epochs,\n",
    "                                validation_data=(X_dev, y_dev),\n",
    "                                workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_acc_and_cel(data_aug_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discuss the Data Augmentation Model:**  \n",
    "From what I've read, the data augmentation method uses the training data to generate a collection on copies with random modifications to each copy. For example, and image can be flipped horizontally or not. Aside from the defaults, When I instantiated the ImageDataGenerator object, I gave it a fill_mode='nearest', cval=0, horizontal_flip=True, and data_format=\"channels_last\". There are also numerous other default parameters can be adjusted, but I arbitrarily chose this subset of parameters because I wanted to make copies with small modifications given the images are already small I don't want them to become too distorted. \n",
    "\n",
    "The model itself was given two maxpooling layers, each of which is followed by a dropout layer that drops 25% of the nodes. Just before being passed to softmax in the output layer, there is one last dropout layer that drops 50% of the nodes. \n",
    "\n",
    "**Observations**   \n",
    "This model did not overfit which I'm very pleased with. This is seen in the plot above where the green(training) and yellow(validation) lines do not converge. preventing the overfitting may largely be a result of having included the dropout layers in the network, as this seems to be good for reducing convergance rates. Overall, this hdata augmentation model had an accuracy on the training of 48% and 50% on the validation. I will use this model on the test set in the next cell because I believe it may generalize the best, as it did not overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate Data Augmentation Model on The Test Set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 192us/step\n",
      "test loss: 1.8918956798553468\n",
      "test accuracy: 0.5045999884605408\n"
     ]
    }
   ],
   "source": [
    "# using the model with the best accuracy, perform the evaluation on the\n",
    "# test set. \n",
    "scores = data_augmentation_model.evaluate(X_test, y_test, verbose=1)\n",
    "print('test loss:', scores[0])\n",
    "print('test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion**  \n",
    "The data augmentation model classified 50% of the images in the test set correctly. This is below the 75% for the best DL classifiers trained for the CIFAR challenge; however, it is still better than random chance, given that there are 100 possible classes to choose from. Were I to go back and do this challenge again, I would focus on tuning the data_augmentation + the dropout regularization. For examply I could change the dropout rate, or change the rotation of the copies in the data augementation set up, and much more. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
